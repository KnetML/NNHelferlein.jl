<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · NNHelferlein.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="NNHelferlein.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">NNHelferlein.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li><a class="tocitem" href="../examples/">Examples</a></li><li class="is-active"><a class="tocitem" href>API</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Layers"><span>Layers</span></a></li><li class="toplevel"><a class="tocitem" href="#Data-providers"><span>Data providers</span></a></li><li><a class="tocitem" href="#Tabular-data"><span>Tabular data</span></a></li><li><a class="tocitem" href="#Image-data"><span>Image data</span></a></li><li class="toplevel"><a class="tocitem" href="#Training"><span>Training</span></a></li><li class="toplevel"><a class="tocitem" href="#Evaluation"><span>Evaluation</span></a></li><li class="toplevel"><a class="tocitem" href="#ImageNet-tools"><span>ImageNet tools</span></a></li></ul></li><li><a class="tocitem" href="../license/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Chains"><a class="docs-heading-anchor" href="#Chains">Chains</a><a id="Chains-1"></a><a class="docs-heading-anchor-permalink" href="#Chains" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.NeuNet" href="#NNHelferlein.NeuNet"><code>NNHelferlein.NeuNet</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">abstract type NeuNet end</code></pre><p>Mother type for DNN hierarchy with implementation for a chain of layers.</p><p><strong>Signatures:</strong></p><pre><code class="language-none">(n::NeuNet)(x) = (for l in n.layers; x = l(x); end; x)
(m::NeuNet)(d::Knet.Data) = mean( m(x,y) for (x,y) in d)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/nets.jl#L6-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.Classifier" href="#NNHelferlein.Classifier"><code>NNHelferlein.Classifier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct Classifier &lt;: NeuNet</code></pre><p>Classifyer with nll loss.</p><p><strong>Signatures:</strong></p><pre><code class="language-none">(m::Classifier)(x,y) = nll(m(x), y)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/nets.jl#L21-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.Regressor" href="#NNHelferlein.Regressor"><code>NNHelferlein.Regressor</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct Regressor</code></pre><p>Regression network with square loss.</p><p><strong>Signatures:</strong></p><pre><code class="language-none">(m::Regression)(x,y) = sum(abs2.( m(x) - y))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/nets.jl#L36-L43">source</a></section></article><h1 id="Layers"><a class="docs-heading-anchor" href="#Layers">Layers</a><a id="Layers-1"></a><a class="docs-heading-anchor-permalink" href="#Layers" title="Permalink"></a></h1><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>Layer</code>. Check Documenter&#39;s build log for details.</p></div></div><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.Dense" href="#NNHelferlein.Dense"><code>NNHelferlein.Dense</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct Dense  &lt;: Layer</code></pre><p>Default Dense layer.</p><p><strong>Constructors:</strong></p><ul><li><code>Dense(w, b, actf)</code>: default constructor</li><li><code>Dense(i::Int, j::Int; actf=sigm)</code>: layer of j neurons with       i inputs.</li><li><code>Dense(h5::HDF5File, group::String; trainable=false, actf=sigm)</code>: layer       imported from a hdf5-file from tensorflow with the       hdf-object hdfo and the group name group.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/layers.jl#L15-L27">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.Conv" href="#NNHelferlein.Conv"><code>NNHelferlein.Conv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct Conv  &lt;: Layer</code></pre><p>Default Conv layer.</p><p><strong>Constructors:</strong></p><ul><li><code>Conv(w, b, padding, actf)</code>: default constructor</li><li><code>Conv(w1::Int, w2::Int,  i::Int, o::Int; actf=relu, padding=0)</code>: layer with   o kernels of size (w1,w2) for an input of i layers.</li><li><code>Conv(h5::HDF5File, group::String; trainable=false, actf=relu)</code>: layer       imported from a hdf5-file from tensorflow with the       hdf-object hdfo and the group name group.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/layers.jl#L61-L73">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.Pool" href="#NNHelferlein.Pool"><code>NNHelferlein.Pool</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct Pool &lt;: Layer</code></pre><p>Pooling layer.</p><p><strong>Constructors:</strong></p><ul><li><code>Pool()</code>: default 2×2 pooling</li><li><code>Pool(k...)</code>: user-defined pooling</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/layers.jl#L112-L120">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.Flat" href="#NNHelferlein.Flat"><code>NNHelferlein.Flat</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct Flat &lt;: Layer</code></pre><p>Default flatten layer.</p><p><strong>Constructors:</strong></p><ul><li><code>Flat()</code>: with no options.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/layers.jl#L129-L136">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.PyFlat" href="#NNHelferlein.PyFlat"><code>NNHelferlein.PyFlat</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct PyFlat &lt;: Layer</code></pre><p>Flatten layer with optional Python-stype flattening (row-major). This layer can be used if pre-trained weight matrices from tensorflow are applied after the flatten layer.</p><p><strong>Constructors:</strong></p><ul><li><code>PyFlat(; python=true)</code>: if true, row-major flatten is performed.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/layers.jl#L143-L152">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.Embed" href="#NNHelferlein.Embed"><code>NNHelferlein.Embed</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct Embed</code></pre><p>Simple type for an embedding layer to embed a virtual onehot-vector into a smaller number of neurons by linear combination. The onehot-vector is virtual, because not the vector, but only the index of the &quot;one&quot; in the vector has to be provided as Integer value (or a minibatch of integers).</p><p><strong>Fields:</strong></p><ul><li>w</li><li>actf</li></ul><p><strong>Constructors:</strong></p><ul><li><code>Embed(i,j; actf=identity) = new(param(j,i), actf):</code> with   input size i, output size j and default activation function idendity.</li></ul><p><strong>Signatures:</strong></p><ul><li><code>(l::Embed)(x) = l.actf.(w[:, permutedims(hcat(x...))])</code> default embedding of input vector x.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/layers.jl#L161-L181">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.Predictions" href="#NNHelferlein.Predictions"><code>NNHelferlein.Predictions</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct Predictions</code></pre><p>Simple wrapper around a Dense layer without activation function that can used as output layer (because all loss-functions of the package assume raw output activations).</p><p><strong>Constructors:</strong></p><ul><li><code>Predictions(i::Int, j:Int)</code>: with   input size i, output size j activation function idendity.</li><li><code>Predictions(h5::HDF5File, group::String; trainable=false)</code>: with   an hdf5-object and group name of the output layer.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/layers.jl#L190-L202">source</a></section></article><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>Softmax</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>Layer</code>. Check Documenter&#39;s build log for details.</p></div></div><h1 id="Data-providers"><a class="docs-heading-anchor" href="#Data-providers">Data providers</a><a id="Data-providers-1"></a><a class="docs-heading-anchor-permalink" href="#Data-providers" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.DataLoader" href="#NNHelferlein.DataLoader"><code>NNHelferlein.DataLoader</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">abstract type DataLoader</code></pre><p>Mother type for minimatch iterators.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/types.jl#L2-L6">source</a></section></article><h2 id="Tabular-data"><a class="docs-heading-anchor" href="#Tabular-data">Tabular data</a><a id="Tabular-data-1"></a><a class="docs-heading-anchor-permalink" href="#Tabular-data" title="Permalink"></a></h2><p>Tabular data is normally provided in table form (csv, ods) row-wise, i.e. one sample per row. The helper functions can read the tables and generate Knet compatible iterators of minibatches.</p><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.dataframe_read" href="#NNHelferlein.dataframe_read"><code>NNHelferlein.dataframe_read</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">dataframe_read(fname)</code></pre><p>Read a data table from an ODS- or CSV-file with one sample per row and return a DataFrame with the data.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/dataframes.jl#L5-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.dataframe_minibatches" href="#NNHelferlein.dataframe_minibatches"><code>NNHelferlein.dataframe_minibatches</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">dataframe_minibatches(data::DataFrames.DataFrame; size=256, ignore=[], teaching=:y, regression=true)</code></pre><p>Make Knet-conform minibatches from a dataframe with one sample per row.</p><ul><li><code>ignore</code>: defines a list of column names to be ignored</li><li><code>teaching</code>: defines the column with teaching input. Default is &quot;:y&quot;</li><li><code>regression</code>: if <code>true</code>, the teaching input is interpreted as               scalar value (converted to Float32); otherwise               teaching input is used as class labels (converted               to UInt8).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/dataframes.jl#L38-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.dataframe_split" href="#NNHelferlein.dataframe_split"><code>NNHelferlein.dataframe_split</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">function dataframe_split(df::DataFrames.DataFrame; teaching=:y, fr=0.2, balanced=true)</code></pre><p>Split data, organised row-wise in a DataFrame into train and valid sets.</p><p><strong>Arguments:</strong></p><ul><li><code>df</code>: data</li><li><code>teaching</code>: name or index of column with teaching input (y)</li><li><code>fr</code>: fraction of data to be used for validation</li><li><code>balanced</code>: if <code>true</code>, result datasets will be balanced by oversampling.             Returned datasets will be bigger as expected             but include the same numbers of samples for each class.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/dataframes.jl#L69-L81">source</a></section></article><h2 id="Image-data"><a class="docs-heading-anchor" href="#Image-data">Image data</a><a id="Image-data-1"></a><a class="docs-heading-anchor-permalink" href="#Image-data" title="Permalink"></a></h2><p>Images as data should be provided in directories with the directory names denoting the class labels. The helpers read from the root of a directory tree in which the first level of sub-dirs tell the class label. All images in the tree under a class label are read as instances of the respective class. The following tree will generate the classes <code>daisy</code>, <code>rose</code> and <code>tulip</code>:</p><pre><code class="language-none">image_dir/
├── daisy
│   ├── 01
│   │   ├── 01
│   │   ├── 02
│   │   └── 03
│   ├── 02
│   │   ├── 01
│   │   └── 02
│   └── others
├── rose
│   ├── big
│   └── small
└── tulip</code></pre><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.ImageLoader" href="#NNHelferlein.ImageLoader"><code>NNHelferlein.ImageLoader</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct ImageLoader &lt;: DataLoader
    dir
    i_paths
    i_classes
    classes
    batchsize
    shuffle
    train
    aug_pipl
    pre_proc
end</code></pre><p>Iterable image loader.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/images.jl#L84-L98">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.mk_image_minibatch" href="#NNHelferlein.mk_image_minibatch"><code>NNHelferlein.mk_image_minibatch</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">function mk_image_minibatch(dir, batchsize; split=false, fr=0.2,
                            balanced=false, shuffle=true, train=true,
                            aug_pipl=nothing, pre_proc=nothing)</code></pre><p>Return an iterable image-loader-object that provides minibatches of path-names of image files, relative to dir.</p><p><strong>Arguments:</strong></p><ul><li><code>dir</code>: base-directory of the image dataset. The first level of       sub-dirs are used as class names.</li><li><code>batchsize</code>: size of minibatches</li></ul><p><strong>Keyword arguments:</strong></p><ul><li><code>split</code>: return two iterators for training and validation</li><li><code>fr</code>: split fraction</li><li><code>balanced</code>: return balanced data (i.e. same number of instances       for all classes). Balancing is achieved via oversampling</li><li><code>shuffle</code>: if true, shuffle the images everytime the iterator       restarts</li><li><code>train</code>: if true, minibatches with (x,y) Tuples are provided,       if false only x (for prediction)</li><li><code>pre_load</code>: if <code>true</code> all images are loaded in advance;       otherwise images are loaded on demand durng training.       (option is <em>not implemented yet!</em>)</li><li><code>aug_pipl</code>: augmentation pipeline for Augmentor.jl. Augmentation       is performed before the pre_proc-function is applied</li><li><code>pre_proc</code>: function with preprocessing       and augmentation algoritms of type x = f(x). In contrast       to the augmentation that modifies images, is <code>pre_proc</code>       working on Arrays{Float32}.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/images.jl#L5-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.get_class_labels" href="#NNHelferlein.get_class_labels"><code>NNHelferlein.get_class_labels</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">function get_class_labels(d::DataLoader)</code></pre><p>Extracts a list of class labels from a DataLoader.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/images.jl#L75-L79">source</a></section></article><h1 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.tb_train!" href="#NNHelferlein.tb_train!"><code>NNHelferlein.tb_train!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">function tb_train!(mdl, opti, trn, vld; epochs=1,
                  lr_decay=0.0, lrd_freq=1, l2=0.0,
                  eval_size=0.2, eval_freq=1,
                  mb_loss_freq=100,
                  cp_freq=1, cp_dir=&quot;checkpoints&quot;,
                  tb_dir=&quot;logs&quot;, tb_name=&quot;run&quot;,
                  tb_text=&quot;&quot;&quot;Description of tb_train!() run.&quot;&quot;&quot;,
                  args...)</code></pre><p>Train function with TensorBoard integration. TB logs are written with the TensorBoardLogger.jl package. The model is updated (in-place) and the trained model is returned.</p><p><strong>Arguments:</strong></p><ul><li><code>mdl</code>: model; i.e. forward-function for the net</li><li><code>opti</code>: Knet-stype optimiser iterator</li><li><code>trn</code>: training data; iterator to provide (x,y)-tuples with       minibatches</li><li><code>vld</code>: validation data; iterator to provide (x,y)-tuples with       minibatches.</li></ul><p><strong>Keyword arguments:</strong></p><p><strong>Optimiser:</strong></p><ul><li><code>epochs=1</code>: number of epochs to train</li><li><code>lr_decay=0.0</code>: Leraning rate decay: factor (&lt;1) to reduce the       lr.</li><li><code>lrd_freq=1</code>: frequency of learning rate decay steps. Default is       to modify the lr after every epoch</li><li><code>l2=0.0</code>: L2 regularisation; implemented as weight decay per       parameter</li><li><code>args...</code>: optional keyword arguments for the optimiser can be specified       (i.e. <code>lr</code>, <code>gamma</code>, ...).</li></ul><p><strong>Model evaluation:</strong></p><ul><li><code>eval_size=0.2</code>: fraction of validation data to be used for calculating       loss and accuracy for train and validation data during training.</li><li><code>eval_freq=1</code>: frequency of evaluation; default=1 means evaluation is       calculated after each epoch. With eval_freq=10 eveluation is       calculated 10 times per epoch.</li><li><code>mb_loss_freq=100</code>: frequency of training loss reporting. default=100       means that 100 loss-values per epoch will be logged to TensorBoard.       If mb<em>loss</em>freq is greater then the number of minibatches,       loss is logged for each minibatch.</li><li><code>cp_freq=1</code>: frequency of model checkpoints written to disk.</li></ul><p>after all other args.         Default is to write the model after each epoch with         name <code>model</code>.</p><ul><li><code>cp_dir=&quot;checkpoints&quot;</code>: directory for checkpoints</li></ul><p><strong>TensorBoard:</strong></p><p>TensorBoard log-directory is created from 3 parts: <code>tb_dir/tb_name/&lt;current date time&gt;</code>.</p><ul><li><code>tb_dir=&quot;logs&quot;</code>: root directory for tensorborad logs.</li><li><code>tb_name=&quot;run&quot;</code>: name of training run. <code>tb_name</code> will be used as       directory name and should not include whitespace</li><li><code>tb_text</code>:  description       to be included in the TensorBoard log as <em>text</em> log.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/train.jl#L1-L60">source</a></section></article><h1 id="Evaluation"><a class="docs-heading-anchor" href="#Evaluation">Evaluation</a><a id="Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluation" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.predict" href="#NNHelferlein.predict"><code>NNHelferlein.predict</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">function predict(mdl, x; softmax=false)</code></pre><p>Return the prediction for x.</p><p><strong>Arguments:</strong></p><p><code>mdl</code>: executable network model <code>x</code>: tensor, minibatch or iterator providing minibatches         of input data <code>softmax</code>: if true and if model is a <code>::Classifier</code> the prediction         softmax probabilities are rezrned instead of raw         activations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/train.jl#L259-L271">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.predict_top5" href="#NNHelferlein.predict_top5"><code>NNHelferlein.predict_top5</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">function predict_top5(mdl, x; top_n=5, classes=nothing)</code></pre><p>Run the model mdl for data in x and prints the top 5 predictions as softmax probabilities.</p><p><strong>Arguments:</strong></p><p><code>top_n</code>: print top <em>n</em> hits instead of <em>5</em> <code>classes</code> may be a list of human readable class labels.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/train.jl#L228-L237">source</a></section></article><h1 id="ImageNet-tools"><a class="docs-heading-anchor" href="#ImageNet-tools">ImageNet tools</a><a id="ImageNet-tools-1"></a><a class="docs-heading-anchor-permalink" href="#ImageNet-tools" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="NNHelferlein.preproc_imagenet" href="#NNHelferlein.preproc_imagenet"><code>NNHelferlein.preproc_imagenet</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">function preproc_imagenet(img)</code></pre><p>Image preprocessing for pre-trained ImageNet examples. Preprocessing includes</p><ul><li>bring RGB colour values into a range 0-255</li><li>standardise of colour values by substracting mean colour values   (103.939, 116.779, 123.68) from RGB</li><li>changing colour channel sequence from RGB to BGR</li></ul><p>Resize is <strong>not</strong> done, because this may be part of the augmentation pipeline.</p><p><strong>Examples:</strong></p><p>The function can be used with the image loader; for prediction with a trained model as:</p><pre><code class="language-julia">pipl = CropRatio(ratio=1.0) |&gt; Resize(224,224)
images = mk_image_minibatch(&quot;./example_pics&quot;, 16;
                    shuffle=false, train=false,
                    aug_pipl=pipl,
                    pre_proc=preproc_imagenet)</code></pre><p>And for training something like:</p><pre><code class="language-julia">pipl = Either(1=&gt;FlipX(), 1=&gt;FlipY(), 2=&gt;NoOp()) |&gt;
       Rotate(-5:5) |&gt;
       ShearX(-5:5) * ShearY(-5:5) |&gt;
       RCropSize(224,224)

dtrn, dvld = mk_image_minibatch(&quot;./example_pics&quot;, 16;
                    split=true, fr=0.2, balanced=false,
                    shuffle=true, train=true,
                    aug_pipl=pipl,
                    pre_proc=preproc_imagenet)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/andreasdominik/NNHelferlein.jl/blob/7b79140a9c5a4cffd9bb91e6c12628819767fd4c/src/imagenet.jl#L2-L39">source</a></section></article><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>precdict_imagenet</code>. Check Documenter&#39;s build log for details.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples/">« Examples</a><a class="docs-footer-nextpage" href="../license/">License »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 3 January 2021 16:50">Sunday 3 January 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
