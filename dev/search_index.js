var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API Reference","title":"API Reference","text":"API doc of all exported functions are listed here:","category":"page"},{"location":"api/#Chains","page":"API Reference","title":"Chains","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractNN\nAbstractChain\nadd_layer!\n+\nprint_network","category":"page"},{"location":"api/#NNHelferlein.AbstractNN","page":"API Reference","title":"NNHelferlein.AbstractNN","text":"abstract type AbstractNN\n\nMother type for AbstractNN hierarchy with implementation for a chain of layers.\n\nSignatures:\n\n(m::AbstractNN)(x): run the AbstractArray x througth all layers and return                       the output\n(m::AbstractNN)(x,y): Calculate the loss for one minibatch x and teaching input y\n(m::AbstractNN)(d::Knet.Data): Calculate the loss for all minibatches in d\n(m::AbstractNN)(d::Tuple): Calculate the loss for all minibatches in d\n(m::AbstractNN)(d::NNHelferlein.DataLoader): Calculate the loss for all minibatches in d                        if teaching input is included (i.e. elements of d are tuples).                       Otherwise return the out of all minibatches as one array with                        samples as columns.\n\n```\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.AbstractChain","page":"API Reference","title":"NNHelferlein.AbstractChain","text":"abstract type AbstractChain\n\nMother type for AbstractChain hierarchy with implementation for a chain of layers. By default every AbstractChain has a property layers with a iterable list of  AbstractLayers or AbstractChains that are executed recursively.\n\nNon-standard Chains in which Layers are not execueted sequnetially (such as ResnetBlocks) must provide a custom implementation with the signature chain(x).\n\nSignatures:\n\n(m::AbstractChain)(x): run the AbstractArray x througth all layers and return                       the output\n\n```\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.add_layer!","page":"API Reference","title":"NNHelferlein.add_layer!","text":"function add_layer!(n::Union{NNHelferlein.AbstractNN, NNHelferlein.AbstractChain}, l)\n\nAdd a layer l or a chain to a model n. The layer is always added  at the end of the chains.  The modified model is returned.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.:+","page":"API Reference","title":"Base.:+","text":"function +(n::Union{NNHelferlein.AbstractNN, NNHelferlein.AbstractChain}, l::Union{AbstractLayer, AbstractChain})\nfunction +(l1::AbstractLayer, l2::Union{AbstractLayer, AbstractChain})\n\nThe plus-operator is overloaded to be able to add layers and chains  to a network.\n\nThe second form returns a new chain if 2 Layers are added.\n\nExample:\n\njulia> mdl = Classifier() + Dense(2,5)\njulia> print_network(mdl)\n\nNNHelferlein neural network summary:\nClassifier with 1 layers,                                           15 params\nDetails:\n \n    Dense layer 2 → 5 with sigm,                                    15 params\n \nTotal number of layers: 1\nTotal number of parameters: 15\n\n\njulia> mdl = mdl + Dense(5,5) + Dense(5,1, actf=identity)\njulia> print_network(mdl)\n\nNNHelferlein neural network summary:\nClassifier with 3 layers,                                           51 params\nDetails:\n \n    Dense layer 2 → 5 with sigm,                                    15 params\n    Dense layer 5 → 5 with sigm,                                    30 params\n    Dense layer 5 → 1 with identity,                                 6 params\n \nTotal number of layers: 3\nTotal number of parameters: 51\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Classifier\nRegressor\nTransformer\nTokenTransformer\nChain\nVAE\nget_beta\nset_beta!","category":"page"},{"location":"api/#NNHelferlein.Classifier","page":"API Reference","title":"NNHelferlein.Classifier","text":"struct Classifier <: AbstractNN\n\nClassifier with default nll loss. An alternative loss function can be supplied as keyword argument. The function must provide a signature to be called as  loss(model(x), y).\n\nConstructors:\n\nClassifier(layers...; loss=Knet.nll)\n\nSignatures:\n\n(m::Classifier)(x,y) = m.loss(m(x), y)\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Regressor","page":"API Reference","title":"NNHelferlein.Regressor","text":"struct Regressor <: AbstractNN\n\nRegression network with square loss as loss function.\n\nConstructors:\n\nRegressor(layers...; loss=mean_squared_error.nll)\n\nSignatures:\n\n(m::Regression)(x,y) = mean(abs2, Array(m(x)) - y)\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Chain","page":"API Reference","title":"NNHelferlein.Chain","text":"struct Chain <: AbstractChain\n\nSimple wrapper to chain layers and execute them one after another.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.VAE","page":"API Reference","title":"NNHelferlein.VAE","text":"struct VAE   <: AbstractNN\n\nType for a generic variational autoencoder.\n\nConstructor:\n\nVAE(encoder, decoder)\n\nSeparate predefind chains (ideally, but not necessarily of type Chain)  for encoder and decoder must be specified. The VAE needs the 2 parameters mean and variance to define the distribution of each code-neuron in the bottleneck-layer. In consequence the encoder output must be 2 times  the size of the decoder input (in case of dense layers: if encoder output is a 8-value vector, 4 codes are defined and the decoder input is a 4-value vector; in case of convolutional layers the number of encoder output channels must be 2 times the number of the encoder input channels - see the examples). \n\nSignatures:\n\n(vae::VAE)(x)\n(vae::VAE)(x,y)\n\nCalled with one argument, predict will be executed;  with two arguments (args x and y should be identical for the autoencoder) the loss will be returned.    \n\nDetails:\n\nThe loss is calculated as the sum of element-wise error squares plus the Kullback-Leibler-Divergence to adapt the distributions of the bottleneck codes:\n\nmathcalL = frac12 sum_i=1^n_outputs (t_i-o_i)^2 - \n               frac12 sum_j=1^n_codes(1 + lnsigma_c_j^2-mu_c_j^2-sigma_c_j^2) \n\nOutput of the autoencoder is cropped to the size of input before loss calculation (and before prediction); i.e. the output has always the same dimensions as the input, even if the last layer generates a bigger shape.\n\nKL-training parameters:\n\nThe parameter β is by default set to 1.0, i.e. mean-squared error and KL  has the same weights. The functions set_beta(vae, beta) and get_beta(vae) can be used to set and get the β used in training. With β=0.0 no KL-loss will be used.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.get_beta","page":"API Reference","title":"NNHelferlein.get_beta","text":"function get_beta(vae::VAE; ramp=false)\n\nReturn a Dict with the current VAE-parameters beta and ramp-up.\n\nArguments:\n\nramp=false: if true, a vector of β for all ramp-up steps is returned.               This way, the ramp-up phase can be visualised:               <img src=\"./assets/vae-beta-range.png\"/>\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.set_beta!","page":"API Reference","title":"NNHelferlein.set_beta!","text":"function setbeta!(vae::VAE, βmax; ramp_up=false, steps=0)\n\nHelper to set the current value of the VAE-parameter beta and ramp-up settings.\n\nVAE loss is calculated as (mean of error squares) + β * (mean of KL divergence).\n\nRamp-up:\n\nIn case of ramp_up=true, β starts with almost 0.0 (sigm(-10.0) ≈4.5e-5) and  reaches almost 1.0 after steps steps, following a sigmoid curve. steps should be more than 25, to avoid rounding errors in the calculation of the derivative of the sigmoid function.\n\n\n\n\n\n","category":"function"},{"location":"api/#Layers","page":"API Reference","title":"Layers","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractLayer","category":"page"},{"location":"api/#NNHelferlein.AbstractLayer","page":"API Reference","title":"NNHelferlein.AbstractLayer","text":"abstract type AbstractLayer\nabstract type Layer\n\nMother type for layers hierarchy. (The type Layer is kept for backward compatibility)\n\n\n\n\n\n","category":"type"},{"location":"api/#Fully-connected-layers","page":"API Reference","title":"Fully connected layers","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Dense\nLinear\nEmbed","category":"page"},{"location":"api/#NNHelferlein.Dense","page":"API Reference","title":"NNHelferlein.Dense","text":"struct Dense  <: AbstractLayer\n\nDefault Dense layer.\n\nConstructors:\n\nDense(w, b, actf): default constructor, w are the weights and b the bias.\nDense(i::Int, j::Int; actf=sigm, init=..): layer of j neurons with       i inputs. Initialiser is xavieruniform for  actf=sigm and       xaviewnormal otherwise.\nDense(h5::HDF5.File, group::String; trainable=false, actf=sigm): kernel and bias are loaded by the specified group.\nDense(h5::HDF5.File, kernel::String, bias::String;       trainable=false, actf=sigm): layer       imported from a hdf5-file from TensorFlow with the       hdf-object h5 and the group name group.\n\n\n\n\n\n","category":"type"},{"location":"api/#Convolutional","page":"API Reference","title":"Convolutional","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Conv\nDeConv\nResNetBlock\nDepthwiseConv\nPool\nUnPool\nPad","category":"page"},{"location":"api/#NNHelferlein.Conv","page":"API Reference","title":"NNHelferlein.Conv","text":"struct Conv  <: AbstractLayer\n\nDefault Conv layer.\n\nConstructors:\n\nConv(w1::Int, w2::Int,  i::Int, o::Int; actf=relu; kwargs...): layer with   o kernels of size (w1,w2) for an input of i channels.\nConv(w1::Int, w2::Int, w3::Int, i::Int, o::Int; actf=relu; kwargs...): layer        with 3-dimensional kernels for 3D convolution        (requires 5-dimensional input)\nConv(w1::Int,  i::Int, o::Int; actf=relu; kwargs...): layer with   o kernels of size (1,w1) for an input of i channels.   This 1-dimensional convolution uses a 2-dimensional kernel with a first    dimension of size 1. Input and output contain an empty firfst dimension   of size 1. If padding, stride or dilation are specified, 2-tuples   must be specified to correspond with the 2-dimensional kernel   (e.g. padding=(0,1) for a 1-padding along the 1D sequence).\n\nConstructors to read parameters from Tensorflow/Keras HDF-files:\n\nConv(h5::HDF5.File, kernel::String, bias::String; trainable=false, actf=Knet.relu,   use_bias=true, kwargs...):       Import parameters from HDF file h5 with kernel and bias specifying       the full path to weights and biases, respectively.\nConv(h5::HDF5.File, group::String; trainable=false, actf=relu, tf=true, use_bias=true):       Import a conv-layer from a default TF/Keras HDF5 file.        If tf=false, group defines the full path to the parameters       group/kernel:0 and group/bias:0.        If tf=true, group defines the  only the group name and        parameters are addressed as model_weights/group/group/kernel:0 and       model_weights/group/group/bias:0.\n\nKeyword arguments:\n\npadding=0: the number of extra zeros implicitly concatenated       at the start and end of each dimension.\nstride=1: the number of elements to slide to reach the next filtering window.\ndilation=1: dilation factor for each dimension.\n... See the Knet documentation for Details:       https://denizyuret.github.io/Knet.jl/latest/reference/#Convolution-and-Pooling.       All keywords to the Knet function conv4() are supported.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Pool","page":"API Reference","title":"NNHelferlein.Pool","text":"struct Pool <: AbstractLayer\n\nPooling layer.\n\nConstructors:\n\nPool(;kwargs...): max pooling; without kwargs, 2-pooling       is performed.\n\nKeyword arguments:\n\nwindow=2: pooling window size (same for all directions)\n...: See the Knet documentation for Details:       https://denizyuret.github.io/Knet.jl/latest/reference/#Convolution-and-Pooling.       All keywords to the Knet function pool are supported.\n\n\n\n\n\n","category":"type"},{"location":"api/#Recurrent","page":"API Reference","title":"Recurrent","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"RecurrentUnit\nRecurrent\nget_hidden_states\nget_cell_states\nset_hidden_states!\nset_cell_states!\nreset_hidden_states!\nreset_cell_states!","category":"page"},{"location":"api/#NNHelferlein.RecurrentUnit","page":"API Reference","title":"NNHelferlein.RecurrentUnit","text":"abstract type RecurrentUnit end\n\nSupertype for all recurrent unit types. Self-defined recurrent units which are a child of RecurrentUnit can be used inside the 'Recurrent' layer.\n\nInterface\n\nAll subtypes of RecurrentUnit must provide the followning:\n\na constructor with signature Type(n_inputs, n_units; kwargs) and   arbitrary keyword arguments.\nan implementation of signature (o::Recurrent)(x)   where x is a 3d- or 2d-array of shape [fan-in, mb-size, 1] or    [fan-in, mb-size].   The function must return the result of one forward    computation for one step and return the hidden state   and set the internal fields h and optionally c.\na field h (to store the last hidden state)\nan optional field c, if the cell state is to be stored   such as in a lstm unit.\n\n\n\n\n\n","category":"type"},{"location":"api/#Transformers","page":"API Reference","title":"Transformers","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"TFEncoder\nTFEncoderLayer\nTFDecoder\nTFDecoderLayer","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"These layers are used by the  Transformer and TokenTransformer types to build Bert-like transformer networks.","category":"page"},{"location":"api/#Others","page":"API Reference","title":"Others","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Flat\nflatten\nPyFlat\nFeatureSelection\nActivation\nSoftmax\nLogistic\nDropout\nBatchNorm\nLayerNorm\nGaussianNoise\nGlobalAveragePooling\nglobal_average_pooling","category":"page"},{"location":"api/#NNHelferlein.Flat","page":"API Reference","title":"NNHelferlein.Flat","text":"struct Flat <: AbstractLayer\n\nDefault flatten layer.\n\nConstructors:\n\nFlat(): with no options.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.flatten","page":"API Reference","title":"NNHelferlein.flatten","text":"flatten(x)\n\nFlatten a tensor to a matrix, preserving the last dimension.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.PyFlat","page":"API Reference","title":"NNHelferlein.PyFlat","text":"struct PyFlat <: AbstractLayer\n\nFlatten layer with optional Python-stype flattening (row-major). This layer can be used if pre-trained weight matrices from tensorflow are applied after the flatten layer.\n\nConstructors:\n\nPyFlat(; python=true): if true, row-major flatten is performed.\n\n\n\n\n\n","category":"type"},{"location":"api/#Attention-Mechanisms","page":"API Reference","title":"Attention Mechanisms","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AttentionMechanism\nAttnBahdanau\nAttnLuong\nAttnDot\nAttnLocation\nAttnInFeed","category":"page"},{"location":"api/#Data-providers","page":"API Reference","title":"Data providers","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DataLoader","category":"page"},{"location":"api/#NNHelferlein.DataLoader","page":"API Reference","title":"NNHelferlein.DataLoader","text":"abstract type DataLoader\n\nMother type for minibatch iterators.\n\n\n\n\n\n","category":"type"},{"location":"api/#Iteration-utilities","page":"API Reference","title":"Iteration utilities","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"PartialIterator\nsplit_minibatches\nMBNoiser\nMBMasquerade\nGPUIterator","category":"page"},{"location":"api/#NNHelferlein.PartialIterator","page":"API Reference","title":"NNHelferlein.PartialIterator","text":"struct PartialIterator <: DataLoader\n\nThe PartialIterator wraps any iterator and will only iterate the states specified in the list indices. \n\nConstuctors\n\nPartialIterator(inner, indices; shuffle=true)\n\nType of the states must match the states of the wrapped iterator inner. A nothing element may be  given to specify the first iterator element.\n\nIf shuffle==true, the list of indices are shuffled every time the PartialIterator is started.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.split_minibatches","page":"API Reference","title":"NNHelferlein.split_minibatches","text":"function split_minibatches(it, at=0.8; shuffle=true)\n\nReturn 2 iterators of type PartialIterator which iterate only parts of the  states of the iterator it.  Be aware that the partial iterators will not contain copies of the data but instead forward the data provided by the iterator it.\n\nThe function can be used to split an iterator of minibatches into train-  and validation iterators, without copying any data. As the PartialIterator objects work with the states of the inner iterator, it is important not to shuffle the inner iterator (in this case the  composition of the partial iterators would change and training and validation data  may be mixed!).\n\nArguments:\n\nit: Iterator to be splitted. The list of allowed states is created by       performing a full iteration once.\nat: Split point. The first returned iterator will include the given        fraction (default: 80%) of the states.\nshuffle: If true, the elements are shuffled at each restart of the iterator.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tabular-data","page":"API Reference","title":"Tabular data","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Tabular data is normally provided in table form (csv, ods) row-wise, i.e. one sample per row. The helper functions can read the tables and generate Knet compatible iterators of minibatches.","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"dataframe_read\ndataframe_minibatch\ndataframe_split\nmk_class_ids","category":"page"},{"location":"api/#Image-data","page":"API Reference","title":"Image data","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Images as data should be provided in directories with the directory names denoting the class labels. The helpers read from the root of a directory tree in which the first level of sub-dirs tell the class label. All images in the tree under a class label are read as instances of the respective class. The following tree will generate the classes daisy, rose and tulip:","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"image_dir/\n├── daisy\n│   ├── 01\n│   │   ├── 01\n│   │   ├── 02\n│   │   └── 03\n│   ├── 02\n│   │   ├── 01\n│   │   └── 02\n│   └── others\n├── rose\n│   ├── big\n│   └── small\n└── tulip","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"ImageLoader\nmk_image_minibatch\nget_class_labels\nimage2array\narray2image\narray2RGB","category":"page"},{"location":"api/#NNHelferlein.ImageLoader","page":"API Reference","title":"NNHelferlein.ImageLoader","text":"struct ImageLoader <: DataLoader\n    dir\n    i_paths\n    i_classes\n    classes\n    batchsize\n    shuffle\n    train\n    aug_pipl\n    pre_proc\n    pre_load\n    i_images\nend\n\nIterable image loader to provide minibatches of images as 4-d-arrays (x,y,rgb,mb).\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.get_class_labels","page":"API Reference","title":"NNHelferlein.get_class_labels","text":"function get_class_labels(d::DataLoader)\n\nExtracts a list of class labels from a DataLoader.\n\n\n\n\n\n","category":"function"},{"location":"api/#Text-data","page":"API Reference","title":"Text data","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"WordTokenizer\nget_tatoeba_corpus\nsequence_minibatch\npad_sequence\ntruncate_sequence","category":"page"},{"location":"api/#Training","page":"API Reference","title":"Training","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"tb_train!","category":"page"},{"location":"api/#Evaluation-and-accuracy","page":"API Reference","title":"Evaluation and accuracy","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"focal_nll\nfocal_bce\npredict\npredict_top5\nminibatch_eval\nsquared_error_acc\nabs_error_acc\nhamming_dist\npeak_finder_acc\nconfusion_matrix","category":"page"},{"location":"api/#ImageNet-tools","page":"API Reference","title":"ImageNet tools","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"preproc_imagenet_vgg\npreproc_imagenet_resnet\npreproc_imagenet_resnetv2,\npredict_imagenet\nget_imagenet_classes","category":"page"},{"location":"api/#Other-utils","page":"API Reference","title":"Other utils","text":"","category":"section"},{"location":"api/#Layers-and-helpers-for-transformers","page":"API Reference","title":"Layers and helpers for transformers","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"PositionalEncoding\nmk_padding_mask\nmk_peek_ahead_mask\ndot_prod_attn\nMultiHeadAttn\nseparate_heads\nmerge_heads","category":"page"},{"location":"api/#Utils-for-array-manipulation","page":"API Reference","title":"Utils for array manipulation","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"crop_array\nblowup_array\nrecycle_array\nde_embed","category":"page"},{"location":"api/#Utils-for-fixing-types-in-GPU-context","page":"API Reference","title":"Utils for fixing types in GPU context","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"init0\nconvert2CuArray\nconvert2KnetArray\nifgpu\nemptyCuArray","category":"page"},{"location":"api/#Utils-for-Bioinformatics","page":"API Reference","title":"Utils for Bioinformatics","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"aminoacid_tokenizer\nembed_blosum62\nembed_vhse8\nEmbedAminoAcids","category":"page"},{"location":"api/#Saving,-loading-and-inspection-of-models","page":"API Reference","title":"Saving, loading and inspection of models","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"save_network\nload_network\ncopy_network\nsummary\nprint_network","category":"page"},{"location":"api/#Base.summary","page":"API Reference","title":"Base.summary","text":"function summary(mdl)\n\nPrint a network summary of any model of Type AbstractNN,  AbstractChain or AbstractLayer.\n\n\n\n\n\n","category":"function"},{"location":"api/#Datasets","page":"API Reference","title":"Datasets","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"dataset_mit_nsr\ndataset_mnist\ndataset_fashion_mnist\ndataset_iris\ndataset_pfam","category":"page"},{"location":"api/#Pretrained-networks","page":"API Reference","title":"Pretrained networks","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"get_vgg16\nget_resnet50v2","category":"page"},{"location":"license/","page":"License","title":"License","text":"The NNHelferlein.jl package is licensed under the MIT License:","category":"page"},{"location":"license/","page":"License","title":"License","text":"Copyright (c) 2023 Andreas Dominik, THM University of Applied Sciences, Gießen, Germany","category":"page"},{"location":"license/","page":"License","title":"License","text":"Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:","category":"page"},{"location":"license/","page":"License","title":"License","text":"The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.","category":"page"},{"location":"license/","page":"License","title":"License","text":"THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","category":"page"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Examples may be used as templates for new projects...     All examples are at GitHub/examples:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Simple MLP: A simple multi-layer perceptron for MNIST classification, build with Knet and Helferlein-types in just one line of code (or so).","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Simple LeNet: A simple LeNet for MNIST classification,  build with help of the Helferlein layers in just two (ok: long) lines of code. \nTraining unbalanced data with help of a focal loss function: A simple MLP with focal loss demonstrate classification of highly unbalanced data.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Vanilla Autoencoder: A simple autoencoder design with help of Knet in Helferlein-style.\nConvolutional Autoencoder: A convolutional autoencoder design with help of Knet in Helferlein-style.\nVariational Autoencoder: Example for a simple VAE utilising the NNHelferlein-type VAE and demonstrating the fascinating regularisation of a VAE.\nSimple sequence-to-sequence network: Simple s2s network to demonstrate how to setup macghine translation with  a rnn.\nSequence-to-sequence RNN for machine translation: RNN to demonstrate how to setup machine translation with  a bidirectional encoder RNN and attention.\nRNN Sequence tagger for annotation of ECGs: RNN to demonstrate how to set-up a sequence tagger to detect heart beats. Only one layer with 8 units is necessary to achieve almost 100% correct predictions.  The example includes the definition on peephole LSTMs to display how to integrate non-standard rnn-units with the NNHelfrelein framework.\nImport a Keras model: The notebook shows the import of a pretrained VGG16 model from Tensorflow/Keras into a Knet-style CNN and its application to example images utilising the Helferlein imagenet-utilities.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Transformer for machine translation: A simple transformer architecture is set up according to the 2017 Vaswani paper Attention is All You Need with help of  NNHelferlein-utils.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Simple Transformer API for Bert-like architectures: A simple transformer architecture is set up with the NNHelferlein transformer API.","category":"page"},{"location":"examples/#Pretrained-Nets","page":"Examples","title":"Pretrained Nets","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Based on the Keras import constructors, it is easy to  import  pretrained models from the TF/Keras ecosystem.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"VGG16\nResNet50 V2","category":"page"},{"location":"changelog/#ChangeLog-of-NNHelferlein-package","page":"Changelog","title":"ChangeLog of NNHelferlein package","text":"","category":"section"},{"location":"changelog/#wip","page":"Changelog","title":"wip","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Padding added to emebdding layer\nGPU selection added (not yet exported)","category":"page"},{"location":"changelog/#v1.3.1-unreleased","page":"Changelog","title":"v1.3.1 - unreleased","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"severeal bioinformatics tools (as embedding, blosum, vhse8)\ndataframe_minibatch default \"y\" changed to nothing.\nBioinformatics: Aminoacid tokenisation added\ngrouped convolutions fixed","category":"page"},{"location":"changelog/#v1.3","page":"Changelog","title":"v1.3","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Transformer API added for Bert-like architectures\nTransformer example\nramp-up of beta added to VAE\ndisambiguate vae signature","category":"page"},{"location":"changelog/#v1.2","page":"Changelog","title":"v1.2","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"imagenet preprocessing fixed for vgg and resnet\nResNetBlock added\nResNet added\nPadding layer added\nprint_network changed to summary\nPretrained nets saved at zenodo and simplified constructors added\nAbstractNN and AbstractLayer added\ncopy model and save/load as JLD2 added","category":"page"},{"location":"changelog/#v1.1.2","page":"Changelog","title":"v1.1.2","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Depthwise conv-layer added (experimental)\nfocal loss functions added to classifier \nFeatureSelection layer added\nexplicit signature added for 3d-convolution\ntrain: possibility to disable tensorboard logs\ntrain: possibility to return losses and accs for  plotting after training","category":"page"},{"location":"changelog/#v1.1.1","page":"Changelog","title":"v1.1.1","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"some docstring cosmetics\nActivation Layers added\nlayer GlobalAveragePoling added\npre-trained vgg example fixed for changed \"import-HDF\"-interface\nhdf5 import with all kwargs possible\nadded: Layer + Layer = Chain\nchangelog added to docu","category":"page"},{"location":"changelog/#v1.1.0","page":"Changelog","title":"v1.1.0","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"documentation for release added\nsplit_minibatches() made stable (never returns an empty iterator)\ndocs slightly re-organised\nGaussian Layer added\nminibatch iterator for masking added","category":"page"},{"location":"changelog/#v1.0.0","page":"Changelog","title":"v1.0.0","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"initial release","category":"page"},{"location":"overview/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"The section provides a brief overview of the functionality provided by NNHelferlen. For more details, please visit the API-Section.","category":"page"},{"location":"overview/#Neural-network-definitions","page":"Overview","title":"Neural network definitions","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"The abstract type AbstractNN provides signatures to be called as","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"(m::AbstractNN)(x): evaluate x (sample or minibatch)\n(m::AbstractNN)(x,y): evaluate x and calculate the loss\n(m::AbstractNN)(d): return the mean loss for a dataset, if d is an iterator               of type Knet.Data or NNHelferlen.DataLoader\n(m::AbstractNN)((x,y)): return the mean loss for a x,y-tuple.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Explicit signatures exist for types Classifier and Regressor with negative log-likelihood and square loss as loss, respectively. For variational autoencoders the type VAE exists.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"The type Chain wraps a list of layers that are executed sequentially.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Types Transformer and TokenTransformer are provided to build Bert-like transformer networks from the rspective TFEncoder  and TFDecoder layers.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"A network summary can be printed with summary(mdl::AbstractNN) and a more detailed list of all layers with print_network(mdl::AbstractNN).","category":"page"},{"location":"overview/#Layer-definitions","page":"Overview","title":"Layer definitions","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Several layers are predefined with executable signatures:","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"MLPs: different flavours of the simple layer:       Dense: default layer for a vector (i.e. sample)          or matrix (i.e. mininbatch) as input with logistic          actvation as default.               Linear: TensorFlow-style layer to process high-dimensional         arrays and identity as default activation.       Embed: embedding layer that adds a first dimension with the          embeddings to the input.\nConvolutional NNs: to build CNNs Conv, DeConv, Pool       UnPool and Flat             layers are provided with standard functionality.       The utilitys include methods for array manipulation, such as       clipping arrays or adding dimensions.\nRecurrent Layers: a Recurrent layer is defined as wrapper        around the basic Knet RNN type.\nOthers: additional layers include (please see the API-section for       a complete list!):       Softmax, Dropout, trainable BatchNorm, trainable LayerNorm.","category":"page"},{"location":"overview/#Attention-Mechanisms","page":"Overview","title":"Attention Mechanisms","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Some attention mechanisms are implemented for use in sequence-to-sequence networks. If possible projections of values are  precomputed to reduce computational cost:","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"AttnBahdanau: concat- or additive-style attention according to       Bahdanau, 2015.\nAttnLuong: multiplicative-or general-stype attention according to       Luong, 2015.\nAttnDot: dot-product-style attention according to       Luong, 2015.\nAttnLocation: dot-product-style attention according to       Luong, 2015.\nAttnInFeed: input-feeding attention according to       Luong, 2015.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"A generalised dot-product attention can be computed from (Query, Key, Value) tuple: dot_prod_attn(q, k, v).","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Helpers for transformer networks include functions for positional encoding, generating padding- and peek-akead-masks and computing scaled multi-headed attention, according to Vaswani, 2017.","category":"page"},{"location":"overview/#Data-provider","page":"Overview","title":"Data provider","text":"","category":"section"},{"location":"overview/#Image-data","page":"Overview","title":"Image data","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"The function mk_image_minibatch() can be used to create an iterator over images, organised in directories, with the first directory-level as class labels.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Helper functions (such as image2array(), array2image(), array2RGB()) can be used to transform image data to arrays. Imagenet-style preprocessing can be achieved with preproc_imagenet(), readable Imagenet class labels of the top predictions are printed by predict_imagenet().","category":"page"},{"location":"overview/#DataFrames","page":"Overview","title":"DataFrames","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Helpers for tabular date include:","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"dataframe_read: read a csv-file and return a DataFrame\ndataframe_split: split tabular data in a DataFrame into train and               validation data; optionally with balancing.\ndataframe_minibatch: data provider to turn tabular data from               a DataFrame (with one sample per row)               into a Knet-like iterator of minibatches of type Knet.Data.\nmk_class_ids(labels): may be used to turn class label strings into               class-IDs.","category":"page"},{"location":"overview/#Texts-and-NLP","page":"Overview","title":"Texts and NLP","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Some utilities are provided for NLP data handling:","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"WordTokenizer: a simple tool to encode words as ids.       The type comes with signatures to en- and decode in both directions.\nget_tatoeba_corpus: download dual-language corpi and provide       corresponding lists of sentences in two languages.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"sequence_minibatch() function returns an iterator to sequence or sequence-to-secuence minibatches. Also helpers for padding and truncating sequences are provided.","category":"page"},{"location":"overview/#Minibatch-iteration-utilities","page":"Overview","title":"Minibatch iteration utilities","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"A number of iterators are provided to wrap and manipulate minibatch iterators:","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"PartialIterator(it, states) returns an iterator that only       iterates the given states of iterator it.\nMBNoiser(it, σ) applies Gaussian noise to the x-values of        minibatches, provided by iterator it.\nMBMasquerade(it, ρ) applies a mask to the x-values of        minibatches, provided by iterator it.","category":"page"},{"location":"overview/#Working-with-pretrained-networks","page":"Overview","title":"Working with pretrained networks","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Layers of pre-trained models can be created from TensorFlow HDF5-parameter files. It is possible to build a network from any pretrained TensorFlow model by importing the parameters by HDF5-constructors for the layers Dense, Conv. The flatten-layer PyFlat allows for Python-like row-major-flattening, necessary to make sure, that the parameters of an imported layer after flattening are in the correct order.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"NNHelferlein provides an increasing number of pretrained  models from the Tensorflow/Keras model zoo, such as vgg or resnet. Please see the reference section for a up-to-date list.","category":"page"},{"location":"overview/#Training","page":"Overview","title":"Training","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Although Knet-style is to avoid havyweight interfaces and train networks with lightweight and flexible optimisers, a train interface is added that provides TensorBoard logs with online reporting of minibatch loss, training and validation loss and accuracy.","category":"page"},{"location":"overview/#Utilities","page":"Overview","title":"Utilities","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"A number of additional utilities are included. Please have a look at the utilities section of the API documentation.","category":"page"},{"location":"overview/#Bioinformatics","page":"Overview","title":"Bioinformatics","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"A number of utilities for bioinformatics are provided, including an amino acid tokenizer to convert amino acid sequences from String to  vectors of integers and embedding of amino acids with BLOSUM62 or VHSE8 parameter sets.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Please have a look at the bioinformatics section of the API documentation.","category":"page"},{"location":"api_overview/#Networks-and-chains","page":"API Overview","title":"Networks and chains","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"AbstractNN - Helferlein network type\nAbstractChain - Helferlein chain type","category":"page"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Classifier - network with NLL loss\nRegressor - network with MSE soll\nVAE - variational autoencoder wrapper The VAE supports ramp-up of the KL-weight beta via the functions set_beta! and get_beta.\nChain","category":"page"},{"location":"api_overview/#Network-helpers","page":"API Overview","title":"Network helpers","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"add_layer!\n+\nsummary\nsave_network - save as jld2 file\nload_network\ncopy_network - copy from and to GPU","category":"page"},{"location":"api_overview/#Layers","page":"API Overview","title":"Layers","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"AbstractLayer","category":"page"},{"location":"api_overview/#Fully-connected-layers","page":"API Overview","title":"Fully connected layers","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Dense\nLinear\nEmbed\nFeatureSelection","category":"page"},{"location":"api_overview/#Convolutional","page":"API Overview","title":"Convolutional","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Layers for convolutional networks:","category":"page"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Conv\nDeConv\nResNetBlock\nDepthwiseConv\nPool\nUnPool\nPad\nFlat\nPyFlat\nGlobalAveragePooling","category":"page"},{"location":"api_overview/#Recurrent","page":"API Overview","title":"Recurrent","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Layers for recurrent networks:","category":"page"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Recurrent - type for recurrent layers\nRecurrentUnit - type for recurrent units","category":"page"},{"location":"api_overview/#Helpers-for-recurrent-networks","page":"API Overview","title":"Helpers for recurrent networks","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"get_hidden_states\nget_cell_states\nset_hidden_states!\nset_cell_states!\nreset_hidden_states!\nreset_cell_states!","category":"page"},{"location":"api_overview/#Other-layers","page":"API Overview","title":"Other layers","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Activation\nSigm\nRelu\nSwish\nSoftmax\nLogistic\nDropout\nBatchNorm\nLayerNorm\nGaussianNoise","category":"page"},{"location":"api_overview/#Attention-Mechanisms","page":"API Overview","title":"Attention Mechanisms","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"AttentionMechanism\nAttnBahdanau\nAttnLuong\nAttnDot\nAttnLocation\nAttnInFeed","category":"page"},{"location":"api_overview/#Tranformer-API","page":"API Overview","title":"Tranformer API","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Transformer - generic transformer type, works on tensors                         of embedded sequences.\nTokenTransformer - generic transformer type, works on                              tokenized sequences.\nTFEncoderLayer\nTFEncoder - Bert-like transformer encoder\nTFDecoderLayer\nTFDecoder - Bert-like transformer decoder\nPositionalEncoding\nmk_padding_mask\nmk_peek_ahead_mask\ndot_prod_attn\nMultiHeadAttn\nseparate_heads\nmerge_heads","category":"page"},{"location":"api_overview/#Activation-functions","page":"API Overview","title":"Activation functions","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Helferlein-style is to provide all functions (such activation  or loss functions) as functions.  Therefore any function from any package or any custom function may be  provided as actf to the layer constructors.","category":"page"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"... see Knet docu  for all activation functions provided by Knet (elu, relu, selu, sigm, ...).\nHelferlein provides some derived funs, such as  leaky_relu, leaky_tanh, leaky_sigm or swish.","category":"page"},{"location":"api_overview/#Data-provider-utilities","page":"API Overview","title":"Data provider utilities","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"DataLoader - type for iterator of minibatches","category":"page"},{"location":"api_overview/#For-tabular-data","page":"API Overview","title":"For tabular data","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"dataframe_read\ndataframe_minibatch - turn a dataframe into minibatches\ndataframe_split\nmk_class_ids","category":"page"},{"location":"api_overview/#For-image-data","page":"API Overview","title":"For image data","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"ImageLoader - turn adirectory structure of image files    into minibatches\nmk_image_minibatch\nget_class_labels","category":"page"},{"location":"api_overview/#Image-to-array-tools","page":"API Overview","title":"Image to array tools","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"image2array\narray2image\narray2RGB","category":"page"},{"location":"api_overview/#ImageNet-tools","page":"API Overview","title":"ImageNet tools","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"preproc_imagenet_vgg\npreproc_imagenet_resnet\npreproc_imagenet_resnetv2\npredict_imagenet\nget_imagenet_classes","category":"page"},{"location":"api_overview/#Text-data","page":"API Overview","title":"Text data","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"WordTokenizer\nsequence_minibatch - turn a text corpus into minibatches\npad_sequence\ntruncate_sequence","category":"page"},{"location":"api_overview/#Text-corpus-example-data-download","page":"API Overview","title":"Text corpus example data download","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"get_tatoeba_corpus","category":"page"},{"location":"api_overview/#Iteration-utilities","page":"API Overview","title":"Iteration utilities","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"PartialIterator\nsplit_minibatches\nMBNoiser\nMBMasquerade","category":"page"},{"location":"api_overview/#Training","page":"API Overview","title":"Training","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"tb_train! - high-level training utility with    tenorboard support and (maybe too) many optional arguments","category":"page"},{"location":"api_overview/#Evaluation-and-accuracy","page":"API Overview","title":"Evaluation and accuracy","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"predict\npredict_top5\nminibatch_eval\nconfusion_matrix","category":"page"},{"location":"api_overview/#Loss-functions","page":"API Overview","title":"Loss functions","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Knet.Ops20.nll -  Cross-entropy for classifiers (aka negative log likelihood)\nKnet.Ops20.bce -  binary cross-entropy for binary classifiers \nfocal_nll\nfocal_bce\n... see Knet docu  for all loss functions provided by Knet.","category":"page"},{"location":"api_overview/#Accuracy-functions","page":"API Overview","title":"Accuracy functions","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Knet.Ops20.accuracy \nsquared_error_acc\nabs_error_acc\nhamming_dist - Hamming distance-like accuracy\npeak_finder_acc - accuracy, suitable for peak detection","category":"page"},{"location":"api_overview/#Other-utils","page":"API Overview","title":"Other utils","text":"","category":"section"},{"location":"api_overview/#Utils-for-array-manipulation","page":"API Overview","title":"Utils for array manipulation","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"crop_array\nblowup_array\nrecycle_array\nde_embed - return argmax for a n-dimensional array","category":"page"},{"location":"api_overview/#Utils-for-fixing-types-in-GPU-context","page":"API Overview","title":"Utils for fixing types in GPU context","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"init0\nconvert2CuArray\nifgpu\nemptyCuArray","category":"page"},{"location":"api_overview/#Datasets","page":"API Overview","title":"Datasets","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"dataset_mit_nsr - logterm ECGs\ndataset_mnist - MNIST\ndataset_iris - Fisher's Iris dataset\nget_tatoeba_corpus - machine translation text corpi\ndataset_pfam - protein sequences dataset","category":"page"},{"location":"api_overview/#Pretrained-networks","page":"API Overview","title":"Pretrained networks","text":"","category":"section"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"Pretrained network weights, derived from Keras applications.","category":"page"},{"location":"api_overview/","page":"API Overview","title":"API Overview","text":"get_vgg16\nget_resnet50v2","category":"page"},{"location":"#NNHelferlein-ADo's-Neural-Networks-Little-Helpers","page":"Introduction","title":"NNHelferlein - ADo's Neural Networks Little Helpers","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The package provides helpers and utilities mainly to be used with the Knet package to build artificial neural networks. The German word Helferlein means something like little helper; please pronounce it like hell-fur-line.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The package follows mainly the Knet-style; i.e. all networks can be trained with the Knet-iterators, all layers can be used together with Knet-style quickly-self-written layers, all Knet-networks can be trained with tb_train(), all data providers can be used together, ...","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The project is hosted here:     https://github.com/KnetML/NNHelferlein.jl","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"NNHelferlein is a registered package and   can be installed with the package manager as:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"] add NNHelferlein","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"or","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg\nPkg.add(\"NNHelferlein\")","category":"page"},{"location":"#First-Steps","page":"Introduction","title":"First Steps","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"NNHelferlein provides quick and easy definition, training and validation of neural network chains.","category":"page"},{"location":"#Symbolic-API","page":"Introduction","title":"Symbolic API","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The Keras-like symbolic API allows for building simple Chains, Classifiers and Regressors from predefined or self-written  layers or functions.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"A first example may be the famous MNIST handwriting recognition  data. Let us assume the data is already loaded in minibatches  in a dtrn iterator and a MLP shall do the job.  The remainder is as little as:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"mlp = Classifier(Dense(784, 256),\n                 Dense(256, 64), \n                 Dense(64, 10, actf=identity)))\n\n\nmlp = tb_train!(mlp, Adam, dtrn, epochs=10, split=0.8,\n                acc_fun=accuracy, eval_size=0.2)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Chains may be built of type Chain, Classifier or Regressor. Simple Chains bring only a signature model(x) to compute  forward computations of a data-sample, a minibatch of data as well as many minibatches of data (the dataset -here: dtrn- must be an iterable object that provides one minibatch on every call).","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Classifiers and Regressors in addition already come with signatures for loss calculation of (x,y)-minibatches (model(x,y))  with crossentropy loss (i.e. negative log-likelihood) and square-loss respectively. This is why  for both types the last layer must not have an activation function (the Helferlein Dense-layer comes with a logistic/sigmoid activation by default; alternatively the Linear-layer can be used that have  no default activation function).","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The function tb_train!() updates the model with the possibility to specify optimiser, training and validation data or an optional split ratio to perform a random  training/validation split. The function offers a multitude of  other options (see the API-documentation for details) and writes tensorboard log-files that allow for online monitoring of the  training progress during training via tensorboard.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"A second way to define a model is the add_layer!()-syntax, here shown for a simple LeNet-like model for the same problem:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"lenet = Classifier()\n\nadd_layer!(lenet, Conv(5,5,1,20))\nadd_layer!(lenet, Pool())\nadd_layer!(lenet, Conv(5,5,20,50))\nadd_layer!(lenet, Pool())\nadd_layer!(lenet, Flat())\nadd_layer!(lenet, Dense(800,512))\nadd_layer!(lenet, Dense(512,10, actf=identity))\n\nmlp = tb_train!(lenet, Adam, dtrn, epochs=10, split=0.8,\n                acc_fun=accuracy, eval_size=0.2)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"As an alternative the +-operator is overloaded to be able to  just add layers to a network:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> mdl = Classifier() + Dense(2,5)\njulia> mdl = mdl + Dense(5,5) + Dense(5,1, actf=identity)\njulia> summary(mdl)\n\nNNHelferlein neural network summary:\nClassifier with 3 layers,                                           51 params\nDetails:\n \n    Dense layer 2 → 5 with sigm,                                    15 params\n    Dense layer 5 → 5 with sigm,                                    30 params\n    Dense layer 5 → 1 with identity,                                 6 params\n \nTotal number of layers: 3\nTotal number of parameters: 51","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Of course, all possibilities can be combined as desired; the following code gives a similar model:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"filters = Chain(Conv(5,5,1,20),\n                Pool(),\n                Conv(5,5,20,50),\n                Pool())\nclassif = Chain(Dense(800,512),\n                Dense(512,10, actf=identity))\n\nlenet2 = Classifier(filters, \n                   Flat())\nadd_layer!(lenet2, classif)\n\nmlp = tb_train!(lenet2, Adam, dtrn, epochs=10, split=0.8,\n                acc_fun=accuracy, eval_size=0.2)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Models can be summarised with summary() or the print_network()-helper:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> summary(lenet)\nNeural network summary:\nClassifier with 7 layers,                                       440812 params\nDetails:\n \n    Conv layer 1 → 20 (5,5) with relu,                             520 params\n    Pool layer,                                                      0 params\n    Conv layer 20 → 50 (5,5) with relu,                          25050 params\n    Pool layer,                                                      0 params\n    Flat layer,                                                      0 params\n    Dense layer 800 → 512 with sigm,                            410112 params\n    Dense layer 512 → 10 with identity,                           5130 params\n \nTotal number of layers: 7\nTotal number of parameters: 440812","category":"page"},{"location":"#Free-model-definition","page":"Introduction","title":"Free model definition","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Another way of model definition gives the full freedom  to define a forward function as pure Julia code.  In the Python world this type of definition is often referred to   as the functional API - in the Julia world we hesitate calling  it an API,  because at the end of the day all is just out-of-the-box Julia! Each model just needs a type, able to store all parameters,  a signature model(x) to compute a forward run and predict the result and a signature model(x,y) to calculate the loss.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"For the predefined Classifier and Regressor types the signatures are  predefined - for own models, this can be easily done in a few lines of code.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The LeNet-like example network for MNIST may be written as:","category":"page"},{"location":"#The-type-and-constructor:","page":"Introduction","title":"The type and constructor:","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"struct LeNet  <: AbstractNN\n    drop1\n    conv1\n    pool1\n    conv2\n    pool2\n    flat\n    drop2\n    mlp\n    predict\n    function LeNet(;drop=0.2)\n        return new(Dropout(drop),\n                   Conv(5,5,1,20),\n                   Pool(),\n                   Conv(5,5,20,50),\n                   Pool(),\n                   Flat(),\n                   Dropout(drop),\n                   Dense(800, 512),\n                   Dense(512, 10, actf=identity))\n    end\nend","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Of course the model may be configured by giving the constructor more parameters. Also the code may be written better organised by combining layers to Chains.","category":"page"},{"location":"#The-forward-signature:","page":"Introduction","title":"The forward signature:","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Brute-force definition:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"function (nn::LeNet)(x::AbstractArray)\n    x = nn.drop1(x)\n    x = nn.conv1(x)\n    x = nn.pool1(x)\n    x = nn.conv2(x)\n    x = nn.pool2(x)\n    x = nn.flat(x)\n    x = nn.drop2(x)\n    x = nn.mlp(x)\n    x = nn.predict(x)\n    return x\nend","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"... or a little bit more elegant:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"\nfunction (nn::LeNet)(x::AbstractArray)\n    layers = (nn.drop1, nn.conv1, nn.pool1, \n              nn.conv2, nn.pool2, nn.flat, \n              nn.drop2, nn.mlp, nn.predict)\n\n    for layer in layers\n        x = layer(x)\n    end\n    return x\nend","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"... or a little bit more elegant:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"function (nn::LeNet)(x::AbstractArray)\n    layers = (nn.drop1, nn.conv1, nn.pool1, \n              nn.conv2, nn.pool2, nn.flat, \n              nn.drop2, nn.mlp, nn.predict)\n\n    return foldl((x,layer)->layer(x), layers, init=x)\nend","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"... or a little more structured:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"function (nn::LeNet)(x::AbstractArray)\n    filters = Chain(nn.drop1, nn.conv1, nn.pool1, \n              nn.conv2, nn.pool2)\n    classifier = Chain(nn.drop2, nn.mlp, nn.predict)\n\n    x = filters(x)\n    x = nn.flat(x)\n    x = classifier(x) \n    return x\nend","category":"page"},{"location":"#The-loss-signature:","page":"Introduction","title":"The loss-signature:","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"function (nn::LeNet)(x,y)\n    return nll(nn(x), y)\nend","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Here we use the Knet.nll() function to calculate the crossentropy. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"That's it!","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Belive it or not - that's all you need to leave the  limitations of the Python world behind and playfully design any  innovative neural network in just a couple of lines of Julia code.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Every object of type LeNet is now a fully functional model, which can be trained with tb_train!().","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"With the signatures defined above, the model can be executed with an array of data (i.e. one minibatch) to get the prediction:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> x,y = first(dtrn)\njulia> lenet = LeNet()\njulia> lenet(x)  |> x->softmax(x, dims=1)\n\n10×8 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n 0.211679   0.214012   0.215643   …  0.208102   0.215791   0.212072\n 0.141102   0.134484   0.132739      0.136913   0.135558   0.134883\n 0.0590838  0.0632321  0.0624464     0.0624035  0.0603432  0.0610424\n 0.221033   0.222141   0.222283      0.223187   0.216619   0.226215\n 0.0203605  0.0201211  0.0212645     0.0207431  0.0212106  0.0206721\n 0.0327132  0.0317656  0.0305331  …  0.0320621  0.033188   0.031767\n 0.181409   0.178959   0.180939      0.182545   0.183172   0.179674\n 0.0242452  0.0240787  0.0251508     0.0251202  0.0253443  0.0244217\n 0.0522174  0.0531308  0.0512095     0.0512213  0.05218    0.0517014\n 0.0561568  0.0580765  0.0577915     0.0577029  0.056594   0.0575527","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"... with a minibatch and the corresponding teaching input (i.e. labels)  to get the loss:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia>  @show y\njulia>  lenet(x,y)\n\ny = Int8[5, 10, 4, 1, 9, 2, 1, 3]\n2.3798099f0","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"... or with an iterator of minibatches to get the mean loss for the dataset:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> lenet(dtrn)\n\n2.6070921f0","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The next step is to have a look at the examples in the GitHub repo:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Pages = [\n    \"examples.md\"\n    ]\nDepth = 2","category":"page"},{"location":"#Overview","page":"Introduction","title":"Overview","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Pages = [\n    \"overview.md\"\n    ]\nDepth = 2","category":"page"},{"location":"#Datasets","page":"Introduction","title":"Datasets","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Some datasets as playground-data are provided with the package. Maybe more will follow...","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"MIT Normal Sinus Rhythm Database is a modified version of the  Physionet dataset, adapted for use in machine leraning (see the docstring of dataset_mit_nsr() for details).\nthe famous MNIST dataset.\nR.A. Fisher's Iris dataset.","category":"page"},{"location":"#API-Reference","page":"Introduction","title":"API Reference","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Pages = [\n    \"api.md\"\n    ]\nDepth = 2","category":"page"},{"location":"#Index","page":"Introduction","title":"Index","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"#Changelog","page":"Introduction","title":"Changelog","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The history can be found here: ChangeLog of NNHelferlein package","category":"page"}]
}
