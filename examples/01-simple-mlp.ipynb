{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e1f3b0e",
   "metadata": {},
   "source": [
    "# Simple Multilayer-Perceptron for MNIST classification\n",
    "\n",
    "Is there any framework out there in which it is easier to to build and train a network \n",
    "as Knet and Helferlein?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d9393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet\n",
    "using NNHelferlein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b8c8b",
   "metadata": {},
   "source": [
    "### Get MNIST data from MLDatasets:\n",
    "\n",
    "The data is already scaled to pixel values between 0.0 and 1.0\n",
    "and the \"0\" is encoded as 10 (because in Julia we have no array-index 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaac21fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtrn = minibatch(xtrn, ytrn, 128; xsize = (28 * 28, :)) = 468-element Knet.Train20.Data{Tuple{CuArray{Float32}, Array{Int64}}}\n",
      "dtst = minibatch(xtst, ytst, 128; xsize = (28 * 28, :)) = 78-element Knet.Train20.Data{Tuple{CuArray{Float32}, Array{Int64}}}\n"
     ]
    }
   ],
   "source": [
    "xtrn, ytrn, xtst, ytst = dataset_mnist()\n",
    "@show dtrn = minibatch(xtrn, ytrn, 128; xsize = (28*28,:))\n",
    "@show dtst = minibatch(xtst, ytst, 128; xsize = (28*28,:));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e94af",
   "metadata": {},
   "source": [
    "The minibatch includes 2-tuples of 784x128 matrix with the flattened pixel data and a 128 vector with the teaching input; i.e. the labels in a range 1-10.    \n",
    "If a functional GPU is detected, the array type is `CuArray`, otherwise its a normal `Array`. \n",
    "Computations with CuArrays are performed on the GPU without need to care in the calling code!\n",
    "\n",
    "Data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d674cb84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784×128 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱                      ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(dtrn)[1]  # first minimatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d1870a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×128 adjoint(::Vector{Int64}) with eltype Int64:\n",
       " 5  10  4  1  9  2  1  3  1  4  3  5  …  2  10  10  2  10  2  7  1  8  6  4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(dtrn)[2]'  # labels of first minibatch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c776522",
   "metadata": {},
   "source": [
    "### Define the MLP with NNHelferlein types:\n",
    "\n",
    "The wrapper type `Classifier` provides a signature with nll-loss \n",
    "(negative log-likelyhood; crossentropy for one-class classification tasks). \n",
    "For correct calculation of the nll, raw activations of the output-layer are \n",
    "needed (no activation function applied):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411cc55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(Any[Dense(P(CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}(256,784)), P(CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}(256)), Knet.Ops20.sigm), Dense(P(CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}(64,256)), P(CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}(64)), Knet.Ops20.sigm), Dense(P(CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}(10,64)), P(CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}(10)), identity)], Knet.Ops20.nll)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = Classifier(Dense(784, 256),\n",
    "                 Dense(256, 64), \n",
    "                 Dense(64, 10, actf=identity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92a0a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNHelferlein neural network of type Classifier:\n",
      " \n",
      "  Dense layer 784 → 256 with sigm,                              200960 params\n",
      "  Dense layer 256 → 64 with sigm,                                16448 params\n",
      "  Dense layer 64 → 10 with identity,                               650 params\n",
      " \n",
      "Total number of layers: 3\n",
      "Total number of parameters: 218058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd323a8b",
   "metadata": {},
   "source": [
    "### Train with Tensorboard logger:\n",
    "\n",
    "This runs in just some seconds on a GPU. \n",
    "\n",
    "Training curves can be visualised with TensorBoard, by pointing TensorBoard to the\n",
    "specified log-directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10bca1da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset for training (80%) and validation (20%).\n",
      "Training 100 epochs with 374 minibatches/epoch and 94 validation mbs.\n",
      "Evaluation is performed every 75 minibatches with 19 mbs.\n",
      "Watch the progress with TensorBoard at:\n",
      "/home/andreas/Documents/Projekte/2022-NNHelferlein_KnetML/NNHelferlein/examples/logs/mlp_run/2022-12-21T16-11-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:55\u001b[39m:24\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished with:\n",
      "Training loss:       6.223597e-6\n",
      "Training accuracy:   1.0\n",
      "Validation loss:     0.12577054\n",
      "Validation accuracy: 0.9796376329787234\n",
      "Test loss:           0.10543932\n",
      "Test accuracy:       0.9814703525641025\n"
     ]
    }
   ],
   "source": [
    "mlp = tb_train!(mlp, Adam, dtrn, epochs=100, split=0.8,\n",
    "        acc_fun=accuracy,\n",
    "        eval_size=0.2, eval_freq=5, mb_loss_freq=100, \n",
    "        tb_name=\"mlp_run\", tb_text=\"NNHelferlein example: MLP\")\n",
    "\n",
    "println(\"Test loss:           $(mlp(dtst))\")\n",
    "println(\"Test accuracy:       $(accuracy(mlp, data=dtst))\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
