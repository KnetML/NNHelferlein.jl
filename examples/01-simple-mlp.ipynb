{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e1f3b0e",
   "metadata": {},
   "source": [
    "# Simple Multilayer-Perceptron for MNIST classification\n",
    "\n",
    "Is there any framework out there in which it is easier to to build and train a network \n",
    "as Knet and Helferlein?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d9393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling NNHelferlein [b9e938e5-d80d-48a2-bb0e-6649b4a98aeb]\n",
      "└ @ Base loading.jl:1423\n"
     ]
    }
   ],
   "source": [
    "using Knet\n",
    "using NNHelferlein\n",
    "using MLDatasets: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b8c8b",
   "metadata": {},
   "source": [
    "### Get MNIST data from MLDatasets:\n",
    "\n",
    "The data is already scaled to pixel values between 0.0 and 1.0.    \n",
    "Only modification necessary is set the class number for the \"0\" to 10\n",
    "(because in Julia we have no array-index 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f8e50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtrn = minibatch(xtrn, ytrn, 128; xsize = (28 * 28, :)) = 468-element Knet.Train20.Data{Tuple{KnetArray{Float32}, Array{Int64}}}\n",
      "dtst = minibatch(xtst, ytst, 128; xsize = (28 * 28, :)) = 78-element Knet.Train20.Data{Tuple{KnetArray{Float32}, Array{Int64}}}\n"
     ]
    }
   ],
   "source": [
    "mnist_dir = joinpath(NNHelferlein.DATA_DIR, \"mnist\")\n",
    "xtrn,ytrn = MNIST.traindata(Float32, dir=mnist_dir)\n",
    "ytrn[ytrn.==0] .= 10\n",
    "@show dtrn = minibatch(xtrn, ytrn, 128; xsize = (28*28,:))\n",
    "\n",
    "xtst,ytst = MNIST.testdata(Float32, dir=mnist_dir)\n",
    "ytst[ytst.==0] .= 10\n",
    "@show dtst = minibatch(xtst, ytst, 128; xsize = (28*28,:));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e94af",
   "metadata": {},
   "source": [
    "The minibatch includes 2-tuples of 784x128 matrix with the flattened pixel data and a 128 vector with the teaching input; i.e. the labels in a range 1-10.    \n",
    "If a functional GPU is detected, the array type is `KnetArray`, otherwise its a normal `Array`. \n",
    "Computations with KnetArrays are performed on the GPU without need to care in the calling code!\n",
    "\n",
    "Data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d674cb84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784×128 Knet.KnetArrays.KnetMatrix{Float32}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱                      ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(dtrn)[1]  # first minimatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d1870a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×128 adjoint(::Vector{Int64}) with eltype Int64:\n",
       " 5  10  4  1  9  2  1  3  1  4  3  5  …  2  10  10  2  10  2  7  1  8  6  4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(dtrn)[2]'  # labels of first minibatch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c776522",
   "metadata": {},
   "source": [
    "### Define the MLP with NNHelferlein types:\n",
    "\n",
    "The wrapper type `Classifier` provides a signature with nll-loss \n",
    "(negative log-likelyhood; crossentropy for one-class classification tasks). \n",
    "For correct calculation of the nll, raw activations of the output-layer are \n",
    "needed (no activation function applied):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411cc55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier((Dense(P(Knet.KnetArrays.KnetMatrix{Float32}(256,784)), P(Knet.KnetArrays.KnetVector{Float32}(256)), Knet.Ops20.sigm), Dense(P(Knet.KnetArrays.KnetMatrix{Float32}(64,256)), P(Knet.KnetArrays.KnetVector{Float32}(64)), Knet.Ops20.sigm), Dense(P(Knet.KnetArrays.KnetMatrix{Float32}(10,64)), P(Knet.KnetArrays.KnetVector{Float32}(10)), identity)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = Classifier(Dense(784, 256),\n",
    "                 Dense(256, 64), \n",
    "                 Dense(64, 10, actf=identity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92a0a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network summary:\n",
      "Classifier with 3 layers,                                       218058 params\n",
      "Details:\n",
      " \n",
      "    Dense layer 784 → 256 with sigm,                            200960 params\n",
      "    Dense layer 256 → 64 with sigm,                              16448 params\n",
      "    Dense layer 64 → 10 with identity,                             650 params\n",
      " \n",
      "Total number of layers: 3\n",
      "Total number of parameters: 218058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_network(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd323a8b",
   "metadata": {},
   "source": [
    "### Train with Tensorboard logger:\n",
    "\n",
    "This runs in just some seconds on a GPU. \n",
    "\n",
    "Training curves can be visualised with TensorBoard, by pointing TensorBoard to the\n",
    "specified log-directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10bca1da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset for training (80%) and validation (20%).\n",
      "Training 10 epochs with 374 minibatches/epoch and 94 validation mbs.\n",
      "Evaluation is performed every 75 minibatches with 19 mbs.\n",
      "Watch the progress with TensorBoard at:\n",
      "/home/andreas/.julia/dev/NNHelferlein/examples/logs/mlp_run/2022-01-23T09-47-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:18\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished with:\n",
      "Training loss:       0.05316837587179666\n",
      "Training accuracy:   0.9854403409090909\n",
      "Validation loss:     0.1047060098300906\n",
      "Validation accuracy: 0.9670877659574468\n",
      "Test loss:           0.088928714\n",
      "Test accuracy:       0.9730568910256411\n"
     ]
    }
   ],
   "source": [
    "mlp = tb_train!(mlp, Adam, dtrn, epochs=10, split=0.8,\n",
    "        acc_fun=accuracy,\n",
    "        eval_size=0.2, eval_freq=5, mb_loss_freq=100, \n",
    "        tb_name=\"mlp_run\", tb_text=\"NNHelferlein example: MLP\")\n",
    "\n",
    "println(\"Test loss:           $(mlp(dtst))\")\n",
    "println(\"Test accuracy:       $(accuracy(mlp, data=dtst))\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
