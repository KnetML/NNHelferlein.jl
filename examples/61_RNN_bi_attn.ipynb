{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d38554",
   "metadata": {},
   "source": [
    "# RNN for machine translation with a bidirectional LSTM encoder and Attention\n",
    "\n",
    "The notebook shows how to implement a recurrent neural network for machine translation \n",
    "with help of Knet and NNHelferlein.\n",
    "The net uses a Tatoeba-corpus to train a bidrirectional lstm encoder and\n",
    "a lstm decoder supported by an \"additive\"-type attention mechanism.\n",
    "\n",
    "The network is inspired by the Bahdanau et al. paper \n",
    "*Neural Machine Translation by Jointly Learning to Align ans Translate*, ICLR 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c4eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Revise\n",
    "#using Random, StatsBase\n",
    "using Knet\n",
    "using NNHelferlein\n",
    "\n",
    "JOBNAME=\"61_RNN_bi_rnn_attn\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3238bbf6",
   "metadata": {},
   "source": [
    "### The seq-2-seq-model\n",
    "\n",
    "The sequence-to-sequence model is simple. We need\n",
    "+ the type\n",
    "+ a constructor\n",
    "+ signatures for training (with 2 sequences as arguments) and for prediction (with only the \n",
    "  source signature as arg)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c11cac",
   "metadata": {},
   "source": [
    "#### Type and constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b2af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct S2S\n",
    "    embed_enc       # embed layer for encoder\n",
    "    embed_dec       # embed layer for decoder\n",
    "    encoder         # encoder rnn\n",
    "    decoder         # decoder rnn\n",
    "    attn            # attention mechanism\n",
    "    combine         # combine attn-context and input\n",
    "    predict         # predict layer (Linear w/o actf)\n",
    "    drop            # dropout layer\n",
    "    voc_in; voc_out # vocab sizes\n",
    "    embed           # embedding depth\n",
    "    units           # number of lstm units in layers\n",
    "\n",
    "    function S2S(n_embed, n_units, n_vocab_in, n_vocab_out)\n",
    "        embed_enc = Embed(n_vocab_in, n_embed)\n",
    "        drop = Dropout(0.1)\n",
    "        embed_dec = Embed(n_vocab_out, n_embed)\n",
    "        encoder = Recurrent(n_embed, n_units, u_type=:lstm, bidirectional=true)\n",
    "        decoder = Recurrent(n_embed, 2*n_units, u_type=:lstm)\n",
    "        attn = AttnBahdanau(2*n_units, 2*n_units)\n",
    "        combine = Linear(2*n_units+n_embed, n_embed, actf=relu)\n",
    "        predict = Linear(2*n_units, n_vocab_out)\n",
    "\n",
    "        return new(embed_enc, embed_dec, encoder, decoder, \n",
    "            attn, combine, \n",
    "            predict, drop,\n",
    "            n_vocab_in, n_vocab_out, n_embed, n_units)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9382d51a",
   "metadata": {},
   "source": [
    "### Training signature\n",
    "\n",
    "includes the following steps:\n",
    "+ run the source sequence througth a rnn layer\n",
    "+ minibatches are built from sequences of similar length - masking of input sequences \n",
    "  is not necessary.\n",
    "+ transfer hidden states from encoder to decoder\n",
    "+ start the decoder with the embedded target sequence with padding mask and and \n",
    "  inject attention-weighted hidden \n",
    "  states from all steps of the encoder sequence.\n",
    "+ calculate and return loss with consideration of a padding mask of the target sequence\n",
    "  (even if the source sequences of a minibatch are the same length, the corresponding \n",
    "  target sequences may have different lengths and need padding and masking of padded positions\n",
    "  in order to ignore them in the loss calculation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb386a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (s2s::S2S)(i, o)\n",
    "\n",
    "    seqlen_i = size(i)[1]\n",
    "    seqlen_o = size(o)[1]\n",
    "    i = reshape(i, seqlen_i, :)\n",
    "    o = reshape(o, seqlen_o, :)\n",
    "    mb = size(i)[end]\n",
    "    \n",
    "    o_mask = mk_padding_mask(o)\n",
    "    \n",
    "    x = s2s.embed_enc(i)   \n",
    "    x = s2s.drop(x)\n",
    "    h_enc = s2s.encoder(x, h=0, c=0, return_all=true)\n",
    "    c = get_cell_states(s2s.encoder)\n",
    "    h = get_hidden_states(s2s.encoder)\n",
    "    \n",
    "    set_cell_states!(s2s.decoder, c)\n",
    "    set_hidden_states!(s2s.decoder, h)\n",
    "\n",
    "    s2s.attn(reset=true)                   # reset projections for new minibatch\n",
    "    h_enc = permutedims(h_enc, (1,3,2))    # steps last for attn\n",
    "    \n",
    "    y = s2s.embed_dec(o)\n",
    "    h_dec = init0(s2s.decoder.n_units, 1, mb)\n",
    "    \n",
    "    for i in 1:seqlen_o-1\n",
    "        y_i = y[:,i,:]\n",
    "        c,α = s2s.attn(h, h_enc)\n",
    "        \n",
    "        y_i = s2s.combine(cat(y_i, c, dims=1))\n",
    "        y_i = reshape(y_i, s2s.embed, 1, mb)\n",
    "        \n",
    "        h = s2s.decoder(y_i, return_all=false, mask=o_mask[[i+1],:])\n",
    "        h = reshape(h, s2s.decoder.n_units, 1, mb)\n",
    "        h_dec = cat(h_dec, h, dims=2)\n",
    "    end\n",
    "            \n",
    "    p = s2s.predict(h_dec[:,2:end,:])\n",
    "    \n",
    "    t = o[2:end,:] .* convert(Array{Int32}, 1 .- o_mask[2:end,:])\n",
    "    loss = nll(p,t)\n",
    "    return loss\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935bb67e",
   "metadata": {},
   "source": [
    "#### Predict signature\n",
    "\n",
    "is very similar to the trainin signature, except of the decoder part\n",
    "that now generates a step of the output sequence in every turn \n",
    "until the `<end>`-token is detected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9177f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (s2s::S2S)(i)\n",
    "    \n",
    "    seqlen_i, mb = size(i)\n",
    "    i = reshape(i, seqlen_i, :)\n",
    "    mb = size(i)[end]\n",
    "\n",
    "    x = s2s.embed_enc(i)\n",
    "    h_enc = s2s.encoder(x, h=0, c=0, return_all=true)\n",
    "\n",
    "    h = get_hidden_states(s2s.encoder)       \n",
    "    c = get_cell_states(s2s.encoder)\n",
    "    set_cell_states!(s2s.decoder, c)\n",
    "    set_hidden_states!(s2s.decoder, h)\n",
    "\n",
    "    output = blowup_array([TOKEN_START], mb)\n",
    "    outstep = blowup_array([TOKEN_START], mb)\n",
    "\n",
    "    s2s.attn(reset=true)                   # reset projections for new minibatch\n",
    "    h_enc = permutedims(h_enc, (1,3,2))    # steps last for attn\n",
    "\n",
    "    MAX_LEN = 16\n",
    "    step = 0\n",
    "    while !all(outstep .== TOKEN_END) && step < MAX_LEN\n",
    "        step += 1\n",
    "        y_i = s2s.embed_dec(outstep)\n",
    "        y_i = reshape(y_i, s2s.embed, mb)\n",
    "        \n",
    "        c,α = s2s.attn(h, h_enc)\n",
    "        y_i = s2s.combine(cat(y_i, c, dims=1))\n",
    "        y_i = reshape(y_i, s2s.embed, 1, mb)\n",
    "\n",
    "        h = s2s.decoder(y_i, return_all=false)\n",
    "        p = s2s.predict(h)\n",
    "        y = softmax(p, dims=1)\n",
    "        outstep = de_embed(y)\n",
    "        output = vcat(output, outstep)\n",
    "    end\n",
    "\n",
    "    return output\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317c653",
   "metadata": {},
   "source": [
    "### Training with a Tatoeba corpus:\n",
    "\n",
    "*NNHelferlein* provides direct access to Tatoeba data. So we can train a rnn on a larger\n",
    "dataset. The Tatoeba German-English corpus includes about 250000 sentences an can be \n",
    "easily accesses as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f586bc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "en, de = get_tatoeba_corpus(\"deu\")\n",
    "en = en[1000:end]; de = de[1000:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "461e68f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare_corpus (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prepare_corpus(source, target; batchsize=128, \n",
    "                        seq_len=16, vocab_size=nothing)\n",
    "    source = clean_sentence.(source)\n",
    "    target = clean_sentence.(target)\n",
    "    \n",
    "    src_vocab = WordTokenizer(source, len=vocab_size)\n",
    "    trg_vocab = WordTokenizer(target, len=vocab_size)\n",
    "    \n",
    "    src = src_vocab(source, add_ctls=false)\n",
    "    trg = trg_vocab(target, add_ctls=true)\n",
    "\n",
    "    src = truncate_sequence.(src, seq_len, end_token=nothing)\n",
    "    trg = truncate_sequence.(trg, seq_len, end_token=TOKEN_END)\n",
    "    \n",
    "    return sequence_minibatch(src, trg, batchsize, shuffle=true, seq2seq=true, \n",
    "                              pad=TOKEN_PAD, partial=true, x_padding=true), \n",
    "           src_vocab, trg_vocab\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1bd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtato, de_vocab, en_vocab = prepare_corpus(de, en, batchsize=128, seq_len=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57c2767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×128 Matrix{Int32}:\n",
       "     5      5      5     5    5      5  …    887    70    70  2243    70  610\n",
       "   401    778    368   778  782   1129      2583   576  2325    77   762  910\n",
       "    33    217     31    26  158    810     40917   160    11     5    20  343\n",
       "    12    455  11564    49  199     14       191  2576    12    27  2060  120\n",
       "   399     31     67  2916    9  10860         5    26   415    33   158   18\n",
       " 32242  12141    106  1384  137     26  …    725  1999   824   287  2812  253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10×128 Matrix{Int32}:\n",
       "    1     1     1     1    1     1  …    1    1     1    1    1     1    1\n",
       "    6     6     6     6    6     6      29   48    48   48   48    48   48\n",
       "  172   275   275   275  784   972      52  322    22   22  193   193  638\n",
       "   24    11    11   135   35  1023      87   16     8    8    6    14   22\n",
       "    7  2283  8768  1251  213    65       7    9   280   56   44  1886  194\n",
       "  200   311   874    46  191     9  …  201  269    27   16    7    22  178\n",
       "    9   791     7     9    7   824     192  193  1653   14  175    23   15\n",
       " 1230    23   118  1618   24   756     167    6    15  176    7    11  270\n",
       "  345    35     2     2   13     2      71  112   598  699   24   459    2\n",
       "    2     2     3     3    2     3       2    2     2    2    2     2    3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = first(dtato)\n",
    "display(x1[1])\n",
    "display(x1[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe767c40",
   "metadata": {},
   "source": [
    "For the training data a single layer of 512 LSTM units and a 3 step learning-rate decay is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9402b2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S2S(Embed(P(Knet.KnetArrays.KnetMatrix{Float32}(1024,40982)), identity), Embed(P(Knet.KnetArrays.KnetMatrix{Float32}(1024,19288)), identity), Recurrent(1024, 1024, :lstm, LSTM(input=1024,hidden=512,bidirectional), true), Recurrent(1024, 1024, :lstm, LSTM(input=1024,hidden=1024), true), AttnBahdanau(Linear(P(Knet.KnetArrays.KnetMatrix{Float32}(1024,1024)), K32(1024)[0.0⋯], identity), Linear(P(Knet.KnetArrays.KnetMatrix{Float32}(1024,1024)), K32(1024)[0.0⋯], identity), Linear(P(Knet.KnetArrays.KnetMatrix{Float32}(1,1024)), K32(1)[0.0⋯], identity), 0.03125, nothing), Linear(P(Knet.KnetArrays.KnetMatrix{Float32}(1024,2048)), P(Knet.KnetArrays.KnetVector{Float32}(1024)), Knet.Ops20.relu), Linear(P(Knet.KnetArrays.KnetMatrix{Float32}(19288,1024)), P(Knet.KnetArrays.KnetVector{Float32}(19288)), identity), Dropout(0.1), 40982, 19288, 1024, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_EMBED = 1024\n",
    "N_UNITS = 512\n",
    "s2s = S2S(N_EMBED, N_UNITS, length(de_vocab), length(en_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afac1afc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset for training (90%) and validation (10%).\n",
      "Training 10 epochs with 1746 minibatches/epoch and 194 validation mbs.\n",
      "Evaluation is performed every 350 minibatches with 97 mbs.\n",
      "Watch the progress with TensorBoard at:\n",
      "/data/aNN/Helferlein/logs/61_RNN_bi_rnn_attn/2022-02-19T16-27-54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:40:24\u001b[39mm15\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to η=5.50e-04 in epoch 3.3\n",
      "Setting learning rate to η=1.00e-04 in epoch 6.7\n",
      "Training finished with:\n",
      "Training loss:       0.18882979670452021\n",
      "Training accuracy:   0.9084787816454619\n",
      "Validation loss:     0.19574543128999852\n",
      "Validation accuracy: 0.9064651601620026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "S2S(Embed(P(Knet.KnetArrays.KnetMatrix{Float32}(1024,40982)), identity), Embed(P(Knet.KnetArrays.KnetMatrix{Float32}(1024,19288)), identity), Recurrent(1024, 1024, :lstm, LSTM(input=1024,hidden=512,bidirectional), true), Recurrent(1024, 1024, :lstm, LSTM(input=1024,hidden=1024), true), AttnBahdanau(Linear(P(Knet.KnetArrays.KnetMatrix{Float32}(1024,1024)), K32(1024)[0.0⋯], identity), Linear(P(Knet.KnetArrays.KnetMatrix{Float32}(1024,1024)), K32(1024)[0.0⋯], identity), Linear(P(Knet.KnetArrays.KnetMatrix{Float32}(1,1024)), K32(1)[0.0⋯], identity), 0.03125, K32(1024,128,7)[3.2399335⋯]), Linear(P(Knet.KnetArrays.KnetMatrix{Float32}(1024,2048)), P(Knet.KnetArrays.KnetVector{Float32}(1024)), Knet.Ops20.relu), Linear(P(Knet.KnetArrays.KnetMatrix{Float32}(19288,1024)), P(Knet.KnetArrays.KnetVector{Float32}(19288)), identity), Dropout(0.1), 40982, 19288, 1024, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s = tb_train!(s2s, Adam, dtato, split=0.9, epochs=10, tb_name=\"$(JOBNAME)\",\n",
    "    acc_fun=hamming_acc, mb_loss_freq=200, eval_freq=5, eval_size=0.5,\n",
    "    lr=0.001, lr_decay=0.0001, lrd_steps=3, lrd_linear=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c3043",
   "metadata": {},
   "source": [
    "Tensorboard output:\n",
    "\n",
    "<img src=\"assets/61-rnn-acc.png\">\n",
    "\n",
    "Loss: <img src=\"assets/61-rnn-loss.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da82ce6c",
   "metadata": {},
   "source": [
    "### Translation:\n",
    "\n",
    "A last signature allows us to directly translate a sentence from German to English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "946547e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "translate (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function translate(inp::T; mdl=s2s, sv=de_vocab, tv=en_vocab) where {T <: AbstractString}\n",
    "    \n",
    "    in_seq = sv(inp, split_words=true, add_ctls=false)\n",
    "    in_seq = reshape(in_seq, (:,1))\n",
    "    out_seq = mdl(in_seq)\n",
    "    return tv(out_seq)\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98156195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> Tom usually listens to classical music <end>\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Tom hört gewöhnlich klassische Musik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dc1ea01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> Tom almost always wears dark clothes <end>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Tom trägt fast immer dunkle Kleidung\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d4a4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> How much beer should I buy <end>\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Wie viel Bier soll ich kaufen?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bac50ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> I need to get some shut-eye <end>\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Ich brauche eine Mütze voll Schlaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdf8264b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> I need to drink more coffee <end>\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Ich muss mehr Kaffee trinken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57e40eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> Tom needs to drink more coffee <end>\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Tom muss mehr Kaffee trinken\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b11e5c1",
   "metadata": {},
   "source": [
    "### Attention factors visualised:\n",
    "\n",
    "The predict signature can be modified to return attention factors instead of the \n",
    "output sequence.\n",
    "The fun `show_attn` displays the attention factors for a translation as heatmap. Light colours show\n",
    "to which encoder positions the decoder gives high attention  in each sequence generation step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b3fdd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Plots.translate in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "show_attn (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "function show_attn(sentence::T; mdl=s2s, sv=de_vocab, tv=en_vocab) where {T <: AbstractString}\n",
    "\n",
    "    in_seq = sv(sentence, split_words=true, add_ctls=false)\n",
    "    in_seq = reshape(in_seq, :,1)\n",
    "    out_seq = mdl(in_seq)\n",
    "    o = tv(out_seq)\n",
    "\n",
    "    # get alphas:\n",
    "    #\n",
    "    seqlen_i = size(in_seq)[1]\n",
    "    seqlen_o = size(out_seq)[1]\n",
    "    in_seq = reshape(in_seq, seqlen_i, :)\n",
    "    out_seq = reshape(out_seq, seqlen_o, :)\n",
    "    mb = 1\n",
    "    \n",
    "    x = mdl.embed_enc(in_seq)   \n",
    "    h_enc = mdl.encoder(x, h=0, c=0, return_all=true)\n",
    "    c = get_cell_states(mdl.encoder)\n",
    "    h = get_hidden_states(mdl.encoder)\n",
    "    \n",
    "    set_cell_states!(mdl.decoder, c)\n",
    "    set_hidden_states!(mdl.decoder, h)\n",
    "\n",
    "    s2s.attn(reset=true)                   # reset projections for new minibatch\n",
    "    h_enc = permutedims(h_enc, (1,3,2))    # steps last for attn\n",
    "    \n",
    "    y = mdl.embed_dec(out_seq)\n",
    "    alpha = init0(seqlen_i, seqlen_o)\n",
    "    \n",
    "    for i in 1:seqlen_o-1\n",
    "        y_i = y[:,i,:]\n",
    "        c,α = s2s.attn(h, h_enc)\n",
    "        \n",
    "        y_i = s2s.combine(cat(y_i, c, dims=1))\n",
    "        y_i = reshape(y_i, s2s.embed, 1, mb)\n",
    "        \n",
    "        h = s2s.decoder(y_i, return_all=false)\n",
    "        h = reshape(h, s2s.decoder.n_units, 1, mb)\n",
    "        alpha[:,i] = α\n",
    "    end\n",
    "    alpha = Array(alpha)\n",
    "            \n",
    "    # visualise:\n",
    "    #\n",
    "    i_words = split(sentence)\n",
    "    o_words = split(o)[2:end]\n",
    "    heatmap(alpha, xrotation=45,\n",
    "            yticks=(1:length(i_words), i_words), \n",
    "            xticks=(1:length(o_words), o_words))\n",
    "    end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64fc13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_attn(\"Tom hört gewöhnlich klassische Musik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee59e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_attn(\"Maria hört gewöhnlich klassische Musik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3290ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_attn(\"Du hast Tom nicht verletzt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_attn(\"Maria hat dich nicht verletzt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345c7347",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"assets/61-attn.png\">\n",
    "\n",
    "The examples show the ability of the attention mechanism to correlate words at different positions of \n",
    "source and target sequence (the last German word *verletzt* corresponds with the 5th word *hurt* in the english sentence; the 3rd German word *dich* corresponds with the last English word *you*: the \n",
    "attention displays that the model has learned these rules.\n",
    "\n",
    "The last sentences are not part of the training - the attention mechanism makes it possible to \n",
    "replace words of a sentence and insert their translation at the correct location of the output sequence\n",
    "(here *You* -> *Mary* and *Tom* -> *you*)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (8 threads) 1.7.0",
   "language": "julia",
   "name": "julia-(8-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
