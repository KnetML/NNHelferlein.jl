{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer: All You Need Is Attention\n",
    "\n",
    "A simple implementation of a BERT-like transformer architecture in Knet/NNHelferlein-style following the iconic *Vaswani, 2017* transformer (fig. from *Vaswani et al. NIPS (2017)* http://arxiv.org/abs/1706.03762 ):\n",
    "\n",
    "<img src=\"assets/80-vaswani-fig-1.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling NNHelferlein [b9e938e5-d80d-48a2-bb0e-6649b4a98aeb]\n",
      "└ @ Base loading.jl:1423\n"
     ]
    }
   ],
   "source": [
    "using Knet, NNHelferlein\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "\n",
    "Tools for masking, positional encoding and multi-headed dot-product-attention are used from *NNHelferlein*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×10 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_peek_ahead_mask(rand(10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "heatmap(Array(positional_encoding_sincos(512, 32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/80-pos-encoding.svg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the self-attention looks like expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(c) = (1024, 16, 64)\n",
      "size(α) = (16, 16, 64)\n"
     ]
    }
   ],
   "source": [
    "m = mk_peek_ahead_mask(zeros(16,64))\n",
    "x = convert2CuArray(randn(1024, 16, 64))\n",
    "c,α = dot_prod_attn(x,x,x, mask=m)\n",
    "@show size(c)   # context\n",
    "@show size(α);  # attention factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(Array(α[:,:,1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/80-self-attn.svg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... multi-headed self-attention generates a stack of attention martrices; here: \n",
    "+ 8 heads\n",
    "+ embedding depth 512\n",
    "+ sequence length 16\n",
    "\n",
    "results in 8 16x16 matrices for each of the 64 sequences of the minibatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(α) = (16, 16, 8, 64)\n"
     ]
    }
   ],
   "source": [
    "mha = MultiHeadAttn(512, 8)\n",
    "x = convert2CuArray(randn(Float32, 512, 16, 64))   # [depth, seq_len, mb_size]\n",
    "c,α = mha(x,x,x)                                  \n",
    "@show size(α);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder:\n",
    "The encoder is built as list of Encoder layers. Each layer performs a multi-headed self-attention. Resiual connections are added to bypass the layers and secured by layer normalisation.\n",
    "\n",
    "The complete Encoder executes all layers after embedding, positional encoding and mask generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct EncoderLayer\n",
    "    mha           # multi-head attn\n",
    "    drop1\n",
    "    norm1         # layer-norm\n",
    "    ffwd1; ffwd2  # final feed forward 4*depth\n",
    "    drop2\n",
    "    norm2\n",
    "\n",
    "    EncoderLayer(depth, n_heads, drop) = new(MultiHeadAttn(depth, n_heads),\n",
    "                                                Dropout(drop),\n",
    "                                                LayerNorm(depth),\n",
    "                                                Linear(depth, depth*4, actf=relu),\n",
    "                                                Linear(depth*4, depth),\n",
    "                                                Dropout(drop),\n",
    "                                                LayerNorm(depth)\n",
    "                                                )\n",
    "    end\n",
    "\n",
    "function (el::EncoderLayer)(x; mask=nothing)\n",
    "\n",
    "    c, α = el.mha(x, x, x, mask=mask)   # always: [depth, seq_len, mb_size]\n",
    "    c = el.drop1(c)\n",
    "    o1 = el.norm1(x .+ c)\n",
    "\n",
    "    o2 = el.ffwd1(o1)                   # [depth*4, seq_len, mb_size]\n",
    "    o2 = el.ffwd2(o2)                   # back: [depth, seq_len, mb_size]\n",
    "    o2 = el.drop2(o2)\n",
    "    o2 = el.norm2(o1 .+ o2)\n",
    "    return o2, α\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Encoder\n",
    "    depth          # embeding depth\n",
    "    embed          # embedding layer\n",
    "    pad_id         # id of padding word\n",
    "    n_layers\n",
    "    layers         # list of actual encoder layers\n",
    "    drop           # dropout layer\n",
    "\n",
    "    Encoder(n_layers, depth, n_heads, vocab_size; pad_id=NNHelferlein.TOKEN_PAD, drop_rate=0.1) =\n",
    "            new(depth,\n",
    "                Embed(vocab_size, depth),\n",
    "                pad_id,\n",
    "                n_layers,\n",
    "                [EncoderLayer(depth, n_heads, drop_rate) for i in 1:n_layers],\n",
    "                Dropout(drop_rate))\n",
    "end\n",
    "\n",
    "\n",
    "function (e::Encoder)(x)\n",
    "\n",
    "    n_seq = size(x)[1]\n",
    "    m_pad = mk_padding_mask(x, pad=e.pad_id, add_dims=true)\n",
    "    x = e.embed(x)                                          # [depth, seq_len, mb_size]\n",
    "    x = x .+ positional_encoding_sincos(e.depth, n_seq)\n",
    "    x = e.drop(x)\n",
    "\n",
    "    for l in e.layers\n",
    "        x,α = l(x, mask=m_pad)\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of the encoder is the encoder hidden state with the same size as the input after embedding\n",
    "\\[*embedding, seq_len, mb_size*\\] (here: embedding depth: 1024, 5 encoder layers, 4 heads and a vocab size of 20000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(henc) = (1024, 16, 64)\n"
     ]
    }
   ],
   "source": [
    "mbx = rand(1:20000, 16, 64)\n",
    "e = Encoder(5, 1024, 4, 20000)\n",
    "henc = e(mbx)\n",
    "@show size(henc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "Decoder layout follows the Encoder and is build from Decoder Layers. The layers are similar to \n",
    "the Encoder Layers with the difference that after the self-attention an attention to the encoder state is added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct DecoderLayer\n",
    "    mhsa          # multi-head attn\n",
    "    drop1\n",
    "    norm1         # layer-norm\n",
    "    mha\n",
    "    drop2\n",
    "    norm2\n",
    "    ffwd1; ffwd2  # final feed forward\n",
    "    drop3\n",
    "    norm3\n",
    "\n",
    "    DecoderLayer(depth, n_heads; drop_rate=0.1) = new(MultiHeadAttn(depth, n_heads),\n",
    "                                             Dropout(drop_rate),\n",
    "                                             LayerNorm(depth),\n",
    "                                             MultiHeadAttn(depth, n_heads),\n",
    "                                             Dropout(drop_rate),\n",
    "                                             LayerNorm(depth),\n",
    "                                             Linear(depth, depth*4, actf=relu),\n",
    "                                             Linear(depth*4, depth),\n",
    "                                             Dropout(drop_rate),\n",
    "                                             LayerNorm(depth)\n",
    "                                             )\n",
    "    end\n",
    "\n",
    "function (dec::DecoderLayer)(x, h_encoder; enc_m_pad=nothing, m_combi=nothing)\n",
    "\n",
    "    self_c, α1 = dec.mhsa(x, x, x, mask=m_combi)    # c: [depth, seq_len, mb_size]\n",
    "                                                    # α: [seq1_len, seq2_len, n_heads, mb_size]\n",
    "    self_c = dec.drop1(self_c)\n",
    "    self_c = dec.norm1(x .+ self_c)\n",
    "\n",
    "    o1, α2 = dec.mha(self_c, h_encoder, h_encoder, mask=enc_m_pad)\n",
    "    o1 = dec.drop2(o1)\n",
    "    o1 = dec.norm2(o1 .+ self_c)\n",
    "\n",
    "    o2 = dec.ffwd1(o1)\n",
    "    o2 = dec.ffwd2(o2)\n",
    "    o2 = dec.drop2(o2)\n",
    "    o2 = dec.norm2(o1 + o2)\n",
    "    return o2, α1, α2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Decoder\n",
    "    depth          # embeding depth\n",
    "    embed          # embedding layer\n",
    "    pad_id\n",
    "    n_layers\n",
    "    layers         # list of actual encoder layers\n",
    "    drop           # dropout layer\n",
    "\n",
    "    Decoder(n_layers, depth, n_heads, vocab_size; pad_id=NNHelferlein.TOKEN_PAD, drop_rate=0.1) =\n",
    "            new(depth,\n",
    "                Embed(vocab_size, depth),\n",
    "                pad_id,\n",
    "                n_layers,\n",
    "                [DecoderLayer(depth, n_heads, drop_rate=drop_rate) for i in 1:n_layers],\n",
    "                Dropout(drop_rate))\n",
    "end\n",
    "\n",
    "function (d::Decoder)(y, h_enc; enc_m_pad=nothing)\n",
    "\n",
    "    n_seq = size(y)[1]\n",
    "    m_peek = mk_peek_ahead_mask(y)                           \n",
    "    m_pad = mk_padding_mask(y, pad=d.pad_id, add_dims=true)  \n",
    "    m_combi = max.(m_peek, m_pad)                            # combined target sequence mask needed\n",
    "                                                             # for self-attn\n",
    "    y = d.embed(y)                                           # [depth, seq_len, mb_size]\n",
    "    y = y .+ positional_encoding_sincos(d.depth, n_seq)\n",
    "    y = d.drop(y)\n",
    "\n",
    "    α2 = init0(0,0,0)\n",
    "    for l in d.layers\n",
    "        y,α1,α2 = l(y, h_enc, enc_m_pad=enc_m_pad, m_combi=m_combi)\n",
    "    end\n",
    "    return y, α2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... test output shapes with random data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(henc) = (1024, 16, 64)\n"
     ]
    }
   ],
   "source": [
    "mbx = rand(1:20000, 16, 64)\n",
    "e = Encoder(5, 1024, 4, 20000)\n",
    "henc = e(mbx)\n",
    "@show size(henc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(p) = (1024, 16, 64)\n",
      "size(α) = (16, 16, 4, 64)\n"
     ]
    }
   ],
   "source": [
    "mby = rand(1:20000, 16, 64)\n",
    "d = Decoder(5, 1024, 4, 20000)\n",
    "p,α = d(mby, henc)\n",
    "@show size(p)\n",
    "@show size(α);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer:\n",
    "\n",
    "The transformer is easily built from the Encoder and Decoder types \n",
    "by calling the  Encoder to generate the encoder hidden state \n",
    "and calling the Decoder to generate the output.\n",
    "A final dense layer (*predict*) is added to restore the result vector of vocabular length \n",
    "from the embedding.\n",
    "\n",
    "This transformer always generates output sequences of the same length as the decoder input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Transformer\n",
    "    encoder\n",
    "    decoder\n",
    "    predict\n",
    "    n_layers\n",
    "    depth\n",
    "    n_heads\n",
    "    x_vocab\n",
    "    y_vocab\n",
    "    drop_rate\n",
    "\n",
    "    Transformer(;n_layers=6, depth=512, n_heads=8,\n",
    "                    x_vocab=nothing, y_vocab=nothing, drop_rate=0.1) = new(\n",
    "                    Encoder(n_layers, depth, n_heads, x_vocab.len, pad_id=TOKEN_PAD, drop_rate=drop_rate),\n",
    "                    Decoder(n_layers, depth, n_heads, y_vocab.len, pad_id=TOKEN_PAD, drop_rate=drop_rate),\n",
    "                    Linear(depth, y_vocab.len),\n",
    "                    n_layers, depth, n_heads, x_vocab, y_vocab, drop_rate\n",
    "                    )\n",
    "end\n",
    "\n",
    "function (tf::Transformer)(x, y)\n",
    "\n",
    "    enc_state = tf.encoder(x)                                        # [depth, seq_len, mb_size]\n",
    "    enc_mask = mk_padding_mask(x, add_dims=true)\n",
    "\n",
    "    dec_state, α2 = tf.decoder(y, enc_state, enc_m_pad=enc_mask)     # [depth, seq_len, mb_size]\n",
    "    out = tf.predict(dec_state)                                      # [y_vocab_len, seq_len, mb_size]\n",
    "    return out, α2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground data\n",
    "\n",
    "For first experiments a tiny but endearing dataset is used and prepared with *NNHelferlein* tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Vector{Int32}}:\n",
       " [1, 7, 9, 6, 2, 3, 3, 3]\n",
       " [1, 10, 5, 13, 2, 3, 3, 3]\n",
       " [1, 15, 5, 11, 2, 3, 3, 3]\n",
       " [1, 7, 12, 8, 14, 6, 2, 3]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de = [\"Ich liebe Julia\",\n",
    "      \"Peter liebt Python\",\n",
    "      \"Susi liebt alle\",\n",
    "      \"Ich programmiere immer in Julia\"]\n",
    "en = [\"I love Julia\",\n",
    "      \"Peter loves Python\",\n",
    "      \"Susi loves them all\",\n",
    "      \"I always code Julia\"]\n",
    "\n",
    "de_vocab = WordTokenizer(de)\n",
    "d = de_vocab(de, add_ctls=true)\n",
    "d = pad_sequence.(d, 8)\n",
    "d = truncate_sequence.(d, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Vector{Int32}}:\n",
       " [1, 7, 10, 5, 2, 3, 3, 3]\n",
       " [1, 9, 6, 11, 2, 3, 3, 3]\n",
       " [1, 12, 6, 14, 13, 2, 3, 3]\n",
       " [1, 7, 15, 8, 5, 2, 3, 3]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab = WordTokenizer(en)\n",
    "e = en_vocab(en, add_ctls=true)\n",
    "e = pad_sequence.(e, 8)\n",
    "e = truncate_sequence.(e, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(mbs) = 2\n",
      "x = Int32[1 1; 7 10; 9 5; 6 13; 2 2; 3 3; 3 3; 3 3]\n",
      "y = Int32[1 1; 7 9; 10 6; 5 11; 2 2; 3 3; 3 3; 3 3]\n"
     ]
    }
   ],
   "source": [
    "mbs = sequence_minibatch(d, e, 2)\n",
    "x,y = first(mbs)\n",
    "@show length(mbs)\n",
    "@show x\n",
    "@show y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformer generates output sequences of the same length as the decoder input (here: 8).\n",
    "\n",
    "Each output vector (i.e. 1st dimension) has the length of the vocab size; the maximum value marks\n",
    "the prediction (not here, because the model is not yet trained!); this can be done with the *NNHelferlein* function `de_embed()` and the tokeniser can be used to back-transform the tokens into words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(o) = (15, 8, 2)\n"
     ]
    }
   ],
   "source": [
    "tf = Transformer(n_layers=5, depth=128, n_heads=4, \n",
    "        x_vocab=de_vocab, y_vocab=en_vocab)\n",
    "o,α = tf(x,y)\n",
    "@show size(o);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×8×2 Array{Int64, 3}:\n",
       "[:, :, 1] =\n",
       " 2  2  2  2  2  2  2  2\n",
       "\n",
       "[:, :, 2] =\n",
       " 2  2  2  2  2  2  2  2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = de_embed(o)   # actually argmax() on the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab(p[:,:,1])   # the tokeniser can be used for de-tokenisation as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model - All You Need is Attention\n",
    "\n",
    "A last model and signature is necessary for training by computing the loss for *(x,y)*-pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mutable struct AllYouNeed\n",
    "    tf # this is the transformer\n",
    "    depth\n",
    "    n_heads\n",
    "    x_vocab\n",
    "    y_vocab\n",
    "    drop_rate\n",
    "    AllYouNeed(;n_layers=6, depth=512, n_heads=8,\n",
    "                x_vocab=nothing, y_vocab=nothing, drop_rate=0.1) = new(\n",
    "                    Transformer(n_layers=n_layers, depth=depth,\n",
    "                                n_heads=n_heads,\n",
    "                                x_vocab=x_vocab, y_vocab=y_vocab,\n",
    "                                drop_rate=drop_rate),\n",
    "                    depth, n_heads,\n",
    "                    x_vocab, y_vocab, drop_rate)\n",
    "end\n",
    "\n",
    "function (ayn::AllYouNeed)(x, y)\n",
    "\n",
    "    # 1st: make shifted y for in and out:\n",
    "    #\n",
    "    y_in = y[1:end-1,:]\n",
    "    y_teach = y[2:end,:]\n",
    "\n",
    "    o, α = ayn.tf(x, y_in)\n",
    "\n",
    "    # calc crossentropy loss (nll) only from positions not masked:\n",
    "    #\n",
    "    mask = y_teach .!= NNHelferlein.TOKEN_PAD\n",
    "    y_m = y_teach .* mask\n",
    "    loss = nll(o, y_m, average=true)\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function (ayn::AllYouNeed)(data::Tuple)\n",
    "    return ayn(data[1], data[2])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.660651f0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn = AllYouNeed(n_layers=5, depth=128, n_heads=4, \n",
    "        x_vocab=de_vocab, y_vocab=en_vocab)\n",
    "\n",
    "ayn(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy:\n",
    "\n",
    "In order to monitor the training an accuracy meassure is needed. *NNHelferlein* provides an \n",
    "accuracy for sequences, based on their *Hamming* distance (`hamming_acc()`). \n",
    "However, the default signature of accuracy functions (to be used with `tb_train()`) \n",
    "assumes that a prediction for a model `mdl`\n",
    "can be obtained by calling `y = mdl(x)`, which is not possible for the transformer, because \n",
    "a decoder input sequence is always necessary to be transformed.\n",
    "Therefore a wrapper must be defined to provide the demanded signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_acc (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_acc(mdl; data=nothing)\n",
    "\n",
    "    tac = Float32(0.0)\n",
    "    for (x,y) in data\n",
    "        y_in = y[1:end-1,:]\n",
    "        y_teach = y[2:end,:]\n",
    "        o, α = mdl.tf(x, y_in)\n",
    "\n",
    "        p = de_embed(o, remove_dim=true)\n",
    "        tac += hamming_acc(p, y_teach, vocab=mdl.y_vocab)\n",
    "    end\n",
    "\n",
    "    return tac / length(data)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14583333333333331"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc(ayn, data=mbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training:\n",
    "The training of the transformen should be started with a warmup-phase with a very small \n",
    "learning rate. The warmup can be performed as a separate training with a \"lerning-rate decay\"\n",
    "that starts with a small and ends with a larger rate (this is actually not a \n",
    "*decay* but a rather an increase):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 100 epochs with 2 minibatches/epoch.\n",
      "Evaluation is performed every 2 minibatches with 2 mbs.\n",
      "Watch the progress with TensorBoard at:\n",
      "/data/aNN/Helferlein/logs/I_love_WARMUP/2022-04-04T06-53-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:20\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to η=5.00e-05 in epoch 20.5\n",
      "Setting learning rate to η=1.00e-04 in epoch 40.5\n",
      "Setting learning rate to η=1.50e-04 in epoch 60.5\n",
      "Setting learning rate to η=2.00e-04 in epoch 80.5\n",
      "Training finished with:\n",
      "Training loss:       0.7795718908309937\n",
      "Training accuracy:   0.8125\n",
      "Training 150 epochs with 2 minibatches/epoch.\n",
      "Evaluation is performed every 2 minibatches with 2 mbs.\n",
      "Watch the progress with TensorBoard at:\n",
      "/data/aNN/Helferlein/logs/I_love_TRAIN/2022-04-04T06-53-48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:29\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to η=7.75e-05 in epoch 30.5\n",
      "Setting learning rate to η=5.50e-05 in epoch 60.5\n",
      "Setting learning rate to η=3.25e-05 in epoch 90.5\n",
      "Setting learning rate to η=1.00e-05 in epoch 120.5\n",
      "Training finished with:\n",
      "Training loss:       0.03347751032561064\n",
      "Training accuracy:   1.0\n"
     ]
    }
   ],
   "source": [
    "mbs = sequence_minibatch(d, e, 2)\n",
    "\n",
    "ayn = AllYouNeed(n_layers=4, depth=128, n_heads=2,\n",
    "                x_vocab=de_vocab, y_vocab=en_vocab, drop_rate=0.1)\n",
    "\n",
    "ayn = tb_train!(ayn, Adam, mbs, epochs=100,\n",
    "                lr=1e-9, lr_decay=2e-4, lrd_steps=5, lrd_linear=true,\n",
    "                tb_name=\"I_love_WARMUP\",\n",
    "                acc_fun=train_acc, eval_size=1, eval_freq=1)\n",
    "ayn = tb_train!(ayn, Adam, mbs, epochs=150,\n",
    "                lr=1e-4, lr_decay=1e-5, lrd_steps=5, lrd_linear=true,\n",
    "                tb_name=\"I_love_TRAIN\",\n",
    "                acc_fun=train_acc, eval_size=1, eval_freq=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual evaluation of the playground data:\n",
    "\n",
    "In order to see how the transformer works, let's run one sequence/sentence \n",
    "step by step trougth the transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×1 Matrix{Int32}:\n",
       " 1\n",
       " 7\n",
       " 9\n",
       " 6\n",
       " 2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = reshape(ayn.x_vocab(\"Ich liebe Julia\", add_ctls=true, split_words=true), :,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Matrix{Int32}:\n",
       " 1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = reshape([ayn.y_vocab(\"<start>\")], 1,1)\n",
    "y = start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell must be executed several times to simulate the prediction loop. \n",
    "Every round will generate one more word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I love Julia <end>\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o, α = ayn.tf(x,y)\n",
    "p = de_embed(o, remove_dim=true)\n",
    "y = vcat(start, p)\n",
    "ayn.y_vocab(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A signature to run predict\n",
    "\n",
    "This predict loop can be run until the `<end>`-token is generated.\n",
    "The loop starts with sequence length 1 by transformint a `<start>`-token \n",
    "in context of the encoder state.\n",
    "\n",
    "Each generated output is extended by adding the `<start>`-token and\n",
    "transformed again, until `<end>` is detected.\n",
    "\n",
    "The signature with an `AbstractString` as input can be used to directly\n",
    "translate a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (ayn::AllYouNeed)(x)\n",
    "\n",
    "    n_seq = length(x)\n",
    "    x = reshape(x, :,1)\n",
    "    START = ayn.y_vocab(\"<start>\")\n",
    "    END = ayn.y_vocab(\"<end>\")\n",
    "    PAD = ayn.y_vocab(\"<pad>\")\n",
    "\n",
    "    start = reshape([START], 1,1)   # make minibatch 2-d-array\n",
    "    y = copy(start)\n",
    "\n",
    "    max_len = 2n_seq                # restrict maximum output len to 2*length of x\n",
    "    i = 1\n",
    "    while (y[end,1] != END) && i <= max_len\n",
    "\n",
    "        out,α = ayn.tf(x,y)\n",
    "        p = de_embed(out, remove_dim=true)\n",
    "        y = vcat(start, p)\n",
    "        i += 1\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "function (ayn::AllYouNeed)(s::AbstractString; alpha=false)\n",
    "\n",
    "    x = ayn.x_vocab(s, split_words=true, add_ctls=true)\n",
    "    p = ayn(x)\n",
    "    return ayn.y_vocab(p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> I love Julia <end>\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Ich liebe Julia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> Peter loves Python <end>\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Peter liebt Python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with a more realistic dataset:\n",
    "\n",
    "Datasets for training translators are not easy to find. A good choice are the corpi \n",
    "provided by Tatoeba with n\\*100000 sentences for some language pairs.\n",
    "However, even these corpi are very limited; sufficient for proof-of-concept but \n",
    "not for produtive applications.\n",
    "\n",
    "*NNHelferlein* provides access to the datasets. Here, the 250000 German-English sentence pairs\n",
    "are downloaded and tuncated or padded to a length of 16 (including `<start>` and `<end>` tokens):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus for language deu is already downloaded.\n",
      "Reading Tatoeba corpus for languages en-deu\n",
      "\r\n",
      "importing sentences: 249000"
     ]
    }
   ],
   "source": [
    "en,de = get_tatoeba_corpus(\"deu\")\n",
    "en = en[20000:end]           # remove sentences with 1 or 2 words\n",
    "de = de[20000:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_vocab = WordTokenizer(de)\n",
    "d = de_vocab(de, add_ctls=true)\n",
    "d = pad_sequence.(d, 16)\n",
    "d = truncate_sequence.(d, 16)\n",
    "\n",
    "en_vocab = WordTokenizer(en)\n",
    "e = en_vocab(en, add_ctls=true)\n",
    "e = pad_sequence.(e, 16)\n",
    "e = truncate_sequence.(e, 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is performed with minibatches of size 128, with a warmup phase and \n",
    "a learning rate starting at 1e-9.\n",
    "\n",
    "Training and validation accurracy and loss are calculated during training after each epoch \n",
    "and only with 1% of the data (this speeds up training; \n",
    "the training curves might become somewhat zigzag as a result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbs = sequence_minibatch(d, e, 128, shuffle=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset for training (90%) and validation (10%).\n",
      "Training 30 epochs with 1611 minibatches/epoch and 179 validation mbs.\n",
      "Evaluation is performed every 1611 minibatches with 2 mbs.\n",
      "Watch the progress with TensorBoard at:\n",
      "/data/aNN/Helferlein/logs/tatoeba_WARMUP/2022-04-03T16-22-59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 1:49:19\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to η=5.00e-05 in epoch 6.0\n",
      "Setting learning rate to η=1.00e-04 in epoch 12.0\n",
      "Setting learning rate to η=1.50e-04 in epoch 18.0\n",
      "Setting learning rate to η=2.00e-04 in epoch 24.0\n",
      "Training finished with:\n",
      "Training loss:       0.9622708159174556\n",
      "Training accuracy:   0.7524227723097118\n",
      "Validation loss:     0.9684001774261783\n",
      "Validation accuracy: 0.7470889747477394\n",
      "Splitting dataset for training (90%) and validation (10%).\n",
      "Training 60 epochs with 1611 minibatches/epoch and 179 validation mbs.\n",
      "Evaluation is performed every 1611 minibatches with 2 mbs.\n",
      "Watch the progress with TensorBoard at:\n",
      "/data/aNN/Helferlein/logs/tatoeba_TRAIN/2022-04-03T18-46-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 5:23:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to η=5.62e-05 in epoch 12.0\n",
      "Setting learning rate to η=3.16e-05 in epoch 24.0\n",
      "Setting learning rate to η=1.78e-05 in epoch 36.0\n",
      "Setting learning rate to η=1.00e-05 in epoch 48.0\n",
      "Training finished with:\n",
      "Training loss:       0.15835840533436046\n",
      "Training accuracy:   0.9454670700536262\n",
      "Validation loss:     0.15705443770942076\n",
      "Validation accuracy: 0.9415936194086587\n"
     ]
    }
   ],
   "source": [
    "ayn = AllYouNeed(n_layers=6, depth=256, n_heads=8,\n",
    "                x_vocab=de_vocab, y_vocab=en_vocab, drop_rate=0.1)\n",
    "\n",
    "GC.gc()\n",
    "ayn = tb_train!(ayn, Adam, mbs, epochs=30, split=0.9,\n",
    "                lr=1e-9, lr_decay=2e-4, lrd_steps=5, lrd_linear=true,\n",
    "#                beta2=0.98, eps=1e-9,\n",
    "                tb_name=\"tatoeba_WARMUP\",\n",
    "                acc_fun=train_acc, eval_size=0.01, eval_freq=1\n",
    "                )\n",
    "GC.gc()\n",
    "ayn = tb_train!(ayn, Adam, mbs, epochs=60, split=0.9,\n",
    "                lr=1e-4, lr_decay=1e-5, lrd_steps=5,\n",
    "#                beta2=0.98, eps=1e-9,\n",
    "                tb_name=\"tatoeba_TRAIN\",\n",
    "                acc_fun=train_acc, eval_size=0.01, eval_freq=1,\n",
    "                cp_freq=5\n",
    "                );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tensorboard-log; Loss:\n",
    "\n",
    "<img src=\"assets/80-tb-log-mbs.png\" width=\"800\">\n",
    "\n",
    "and training-/validation accuracy:\n",
    "\n",
    "<img src=\"assets/80-tb-logs-acc.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using JLD2\n",
    "# jldsave(\"allyouneed.jld2\"; ayn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:\n",
    "#### Sentences from the training data:\n",
    "\n",
    "**deu:** \"Ich höre immer gerne klassische Musik in meiner Freizeit\"    \n",
    "**eng:** \"I always enjoy listening to classical music when I have some free time\"    \n",
    "and: \"I always enjoy listening to classical music in my free time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> I always enjoy listening to classical music in my spare time <end>\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Ich höre immer gerne klassische Musik in meiner Freizeit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**deu:** \"Tom singt gerne in der Badewanne\"    \n",
    "**eng:** \"Tom likes to sing in the bathtub\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> Tom likes to sing in the bathtub <end>\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Tom singt gerne in der Badewanne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentences that are *not* in the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> I always like to listen to classical music in the car <end>\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Ich höre immer gerne klassische Musik im Auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> Tom always likes to listen to classical music in the car <end>\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Tom hört immer gerne klassische Musik im Auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> Tom likes to sing in the car <end>\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Tom singt gerne im Auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> My aunt wears a green dress in the car <end>\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Meine Tante trägt ein grünes Kleid im Auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> My dog is driving the car into the garage <end>\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Mein Hund fährt das Auto in die Garage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> My boss likes coffee <end>\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Mein Chef trinkt gerne Kaffee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> I don t want to buy this carpet <end>\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Ich möchte diesen Teppich nicht kaufen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> I m going to the office now <end>\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"ich gehe jetzt ins Büro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> This kind of works is excellent <end>\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayn(\"Dieses Ding funktioniert erstaunlich gut\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (8 threads) 1.7.0",
   "language": "julia",
   "name": "julia-(8-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
